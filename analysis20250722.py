import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import warnings
import io
import base64
from reportlab.lib.pagesizes import A4, landscape
from reportlab.platypus import (SimpleDocTemplate, Table, TableStyle, 
                                Paragraph, Spacer)
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ë“±ë¡ (Windows ê¸°ì¤€)
try:
    pdfmetrics.registerFont(TTFont('NanumGothic', 
                                   'C:/Windows/Fonts/malgun.ttf'))
    KOREAN_FONT = 'NanumGothic'
except (OSError, FileNotFoundError):
    KOREAN_FONT = 'Helvetica'  # í°íŠ¸ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê´€ì„¸ë²•ì¸ìš°ì‹  ì¢…í•© ë¶„ì„ ì‹œìŠ¤í…œ(ìˆ˜ì…)",
    page_icon="ğŸ¢",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f4e79;
        text-align: center;
        margin-bottom: 2rem;
        padding: 1rem;
        background: linear-gradient(90deg, #f0f8ff, #e6f3ff);
        border-radius: 10px;
        border-left: 5px solid #1f4e79;
    }
    .tab-header {
        font-size: 1.8rem;
        font-weight: bold;
        margin-bottom: 1rem;
        padding: 0.5rem;
        border-radius: 8px;
    }
    .internal-tab { background-color: #e8f4fd; color: #1f4e79; }
    .client-tab { background-color: #fff2e8; color: #d68910; }
    .forwarder-tab { background-color: #e8f8f5; color: #239b56; }
    
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #4472c4;
    }
    .complexity-high { border-left-color: #e74c3c !important; }
    .complexity-medium { border-left-color: #f39c12 !important; }
    .complexity-low { border-left-color: #27ae60 !important; }
    
    .insight-box {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #17a2b8;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

class CustomsAnalyzer:
    """ê´€ì„¸ì‚¬ ì—…ë¬´ ì¢…í•© ë¶„ì„ í´ë˜ìŠ¤ (3ì°¨ì› ë¶„ì„)"""
    
    def __init__(self, df, weights=None):
        self.df = df.copy()
        # ê¸°ë³¸ ê°€ì¤‘ì¹˜ ì„¤ì •
        self.weights = weights or {
            'lane_weight': 1.0,
            'spec_weight': 0.5,
            'requirement_weight': 10.0,
            'exemption_weight': 10.0,
            'fta_weight': 10.0,
            'transaction_weight': 5.0,
            'trader_weight': 5.0
        }
        self.prepare_data()
    
    def prepare_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        self.df.columns = self.df.columns.str.strip()
        
        # ë””ë²„ê¹…: ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(self.df.columns)}")
        
        # ë‚ ì§œ ì²˜ë¦¬ - ì—¬ëŸ¬ ë‚ ì§œ ì»¬ëŸ¼ ì¤‘ ì‚¬ìš© ê°€ëŠ¥í•œ ê²ƒì„ ì°¾ì•„ì„œ ì‚¬ìš©
        date_success = False
        
        # 1ìˆœìœ„: ìˆ˜ë¦¬ì¼ì
        if 'ìˆ˜ë¦¬ì¼ì' in self.df.columns:
            print(f"ìˆ˜ë¦¬ì¼ì ì»¬ëŸ¼ ë°œê²¬! ìƒ˜í”Œ ë°ì´í„°: {self.df['ìˆ˜ë¦¬ì¼ì'].head()}")
            
            self.df['ìˆ˜ë¦¬ì¼ì_parsed'] = (
                self.df['ìˆ˜ë¦¬ì¼ì'].apply(self.parse_date_string)
            )
            self.df['ìˆ˜ë¦¬ì¼ì_parsed'] = pd.to_datetime(
                self.df['ìˆ˜ë¦¬ì¼ì_parsed'], errors='coerce'
            )
            
            parsed_count = self.df['ìˆ˜ë¦¬ì¼ì_parsed'].notna().sum()
            total_count = len(self.df)
            print(f"ìˆ˜ë¦¬ì¼ì íŒŒì‹± ì„±ê³µ: {parsed_count}/{total_count}ê°œ")
            
            if parsed_count > 0:
                date_success = True
                self.df['ë‚ ì§œ_ê¸°ì¤€'] = self.df['ìˆ˜ë¦¬ì¼ì_parsed']
                print("âœ… ìˆ˜ë¦¬ì¼ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # 2ìˆœìœ„: ì‹ ê³ ì¼ì (ìˆ˜ë¦¬ì¼ìê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°)
        if not date_success and 'ì‹ ê³ ì¼ì' in self.df.columns:
            print(f"ì‹ ê³ ì¼ì ì»¬ëŸ¼ í™•ì¸! ìƒ˜í”Œ ë°ì´í„°: {self.df['ì‹ ê³ ì¼ì'].head()}")
            
            self.df['ì‹ ê³ ì¼ì_parsed'] = (
                self.df['ì‹ ê³ ì¼ì'].apply(self.parse_date_string)
            )
            self.df['ì‹ ê³ ì¼ì_parsed'] = pd.to_datetime(
                self.df['ì‹ ê³ ì¼ì_parsed'], errors='coerce'
            )
            
            parsed_count = self.df['ì‹ ê³ ì¼ì_parsed'].notna().sum()
            print(f"ì‹ ê³ ì¼ì íŒŒì‹± ì„±ê³µ: {parsed_count}/{total_count}ê°œ")
            
            if parsed_count > 0:
                date_success = True
                self.df['ë‚ ì§œ_ê¸°ì¤€'] = self.df['ì‹ ê³ ì¼ì_parsed']
                print("âœ… ì‹ ê³ ì¼ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # 3ìˆœìœ„: ì…ë ¥ì¼ì‹œ (ë‹¤ë¥¸ ë‚ ì§œë“¤ì´ ì—†ëŠ” ê²½ìš°)
        if not date_success and 'ì…ë ¥ì¼ì‹œ' in self.df.columns:
            print(f"ì…ë ¥ì¼ì‹œ ì»¬ëŸ¼ í™•ì¸! ìƒ˜í”Œ ë°ì´í„°: {self.df['ì…ë ¥ì¼ì‹œ'].head()}")
            
            self.df['ì…ë ¥ì¼ì‹œ_parsed'] = pd.to_datetime(
                self.df['ì…ë ¥ì¼ì‹œ'], errors='coerce'
            )
            
            parsed_count = self.df['ì…ë ¥ì¼ì‹œ_parsed'].notna().sum()
            print(f"ì…ë ¥ì¼ì‹œ íŒŒì‹± ì„±ê³µ: {parsed_count}/{total_count}ê°œ")
            
            if parsed_count > 0:
                date_success = True
                self.df['ë‚ ì§œ_ê¸°ì¤€'] = self.df['ì…ë ¥ì¼ì‹œ_parsed']
                print("âœ… ì…ë ¥ì¼ì‹œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # ë‚ ì§œ ê¸°ì¤€ì´ ìˆëŠ” ê²½ìš° ìš”ì¼ ê³„ì‚°
        if date_success and 'ë‚ ì§œ_ê¸°ì¤€' in self.df.columns:
            self.df['ìš”ì¼'] = self.df['ë‚ ì§œ_ê¸°ì¤€'].dt.day_name()
            self.df['ìš”ì¼_í•œê¸€'] = self.df['ë‚ ì§œ_ê¸°ì¤€'].dt.dayofweek.map({
                0: 'ì›”ìš”ì¼', 1: 'í™”ìš”ì¼', 2: 'ìˆ˜ìš”ì¼', 3: 'ëª©ìš”ì¼', 4: 'ê¸ˆìš”ì¼',
                5: 'í† ìš”ì¼', 6: 'ì¼ìš”ì¼'
            })
            
            # ë””ë²„ê¹…: ìš”ì¼ë³„ ê±´ìˆ˜ í™•ì¸
            weekday_counts = self.df['ìš”ì¼_í•œê¸€'].value_counts()
            print(f"âœ… ìš”ì¼ë³„ ê±´ìˆ˜: {weekday_counts.to_dict()}")
        else:
            # ëª¨ë“  ë‚ ì§œê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
            self.df['ìš”ì¼'] = None
            self.df['ìš”ì¼_í•œê¸€'] = None
            print("âŒ ê²½ê³ : ëª¨ë“  ë‚ ì§œ ì»¬ëŸ¼ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
            
        # í˜¸í™˜ì„±ì„ ìœ„í•´ ê¸°ì¡´ ì»¬ëŸ¼ë“¤ë„ ìœ ì§€
        if 'ì‹ ê³ ì¼ì' in self.df.columns and 'ì‹ ê³ ì¼ì_parsed' not in self.df.columns:
            self.df['ì‹ ê³ ì¼ì_parsed'] = (
                self.df['ì‹ ê³ ì¼ì'].apply(self.parse_date_string)
            )
            self.df['ì‹ ê³ ì¼ì_parsed'] = pd.to_datetime(
                self.df['ì‹ ê³ ì¼ì_parsed'], errors='coerce'
            )
    
    def parse_date_string(self, date_str):
        """ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹± (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)"""
        if pd.isna(date_str):
            return None
        
        try:
            date_str = str(date_str).strip()
            
            # ì´ë¯¸ datetime í˜•ì‹ì¸ ê²½ìš°
            if isinstance(date_str, str) and 'Timestamp' in str(type(date_str)):
                return pd.to_datetime(date_str)
            
            # YYYYMMDD í˜•ì‹ (8ìë¦¬)
            if len(date_str) == 8 and date_str.isdigit():
                year, month, day = date_str[:4], date_str[4:6], date_str[6:8]
                return pd.to_datetime(f"{year}-{month}-{day}")
            
            # YYYY-MM-DD í˜•ì‹
            if '-' in date_str and len(date_str) == 10:
                return pd.to_datetime(date_str)
            
            # YYYY/MM/DD í˜•ì‹
            if '/' in date_str:
                return pd.to_datetime(date_str)
            
            # ê·¸ì™¸ í˜•ì‹ì€ pandasì—ê²Œ ë§¡ê¹€
            return pd.to_datetime(date_str, errors='coerce')
            
        except Exception:
            return None
    
    def update_weights(self, weights):
        """ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸"""
        self.weights.update(weights)
    
    def calculate_complexity_score(self, data, group_col='ì‹ ê³ ë²ˆí˜¸'):
        """7ì°¨ì› ë³µì¡ë„ ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì ìš©)"""
        # ì‹ ê³ ë²ˆí˜¸ë³„ ê·¸ë£¹í™” (ì¤‘ë³µì œê±°)
        decl_grouped = data.groupby(group_col).agg({
            'ì´ë€ìˆ˜': 'first',
            'ì´ê·œê²©ìˆ˜': 'first', 
            'ê´€ì„¸ê°ë©´êµ¬ë¶„': 'first',
            'ì›ì‚°ì§€ì¦ëª…ìœ ë¬´': 'first',
            'ê±°ë˜êµ¬ë¶„': 'nunique',  # ê±°ë˜êµ¬ë¶„ ì¢…ë¥˜ ìˆ˜
            'ë¬´ì—­ê±°ë˜ì²˜ìƒí˜¸': 'nunique',  # ë¬´ì—­ê±°ë˜ì²˜ ì¢…ë¥˜ ìˆ˜
            'ë°œê¸‰ì„œë¥˜ëª…': lambda x: x.notna().sum()  # ìˆ˜ì…ìš”ê±´ ìˆ˜
        }).reset_index()
        
        # ë³µì¡ë„ ê³„ì‚°
        complexity_scores = []
        
        for _, row in decl_grouped.iterrows():
            score = 0
            
            # 1. ì´ë€ìˆ˜ (ê°€ì¤‘ì¹˜ ì ìš©)
            score += (row.get('ì´ë€ìˆ˜', 0) * self.weights['lane_weight']) if pd.notna(row.get('ì´ë€ìˆ˜', 0)) else 0
            
            # 2. ì´ê·œê²©ìˆ˜ (ê°€ì¤‘ì¹˜ ì ìš©)
            score += (row.get('ì´ê·œê²©ìˆ˜', 0) * self.weights['spec_weight']) if pd.notna(row.get('ì´ê·œê²©ìˆ˜', 0)) else 0
            
            # 3. ìˆ˜ì…ìš”ê±´ ìˆ˜ (ê°€ì¤‘ì¹˜ ì ìš©)
            score += row.get('ë°œê¸‰ì„œë¥˜ëª…', 0) * self.weights['requirement_weight']
            
            # 4. ê°ë©´ ì ìš© (ê°€ì¤‘ì¹˜ ì ìš©)
            if pd.notna(row.get('ê´€ì„¸ê°ë©´êµ¬ë¶„')) and str(row.get('ê´€ì„¸ê°ë©´êµ¬ë¶„')).strip():
                score += self.weights['exemption_weight']
                
            # 5. ì›ì‚°ì§€ì¦ëª… (ê°€ì¤‘ì¹˜ ì ìš©)
            if row.get('ì›ì‚°ì§€ì¦ëª…ìœ ë¬´') == 'Y':
                score += self.weights['fta_weight']
            
            # 6. ê±°ë˜êµ¬ë¶„ ì¢…ë¥˜ ìˆ˜ (ê°€ì¤‘ì¹˜ ì ìš©)
            score += row.get('ê±°ë˜êµ¬ë¶„', 1) * self.weights['transaction_weight']
            
            # 7. ë¬´ì—­ê±°ë˜ì²˜ ì¢…ë¥˜ ìˆ˜ (ê°€ì¤‘ì¹˜ ì ìš©)  
            score += row.get('ë¬´ì—­ê±°ë˜ì²˜ìƒí˜¸', 1) * self.weights['trader_weight']
            
            complexity_scores.append(score)
        
        return np.mean(complexity_scores) if complexity_scores else 0
    
    def analyze_by_author(self):
        """ì‘ì„±ìë³„ ë¶„ì„ (ë‚´ë¶€ ê´€ë¦¬ìš©)"""
        if 'ì‘ì„±ì' not in self.df.columns:
            return pd.DataFrame()
        
        valid_data = self.df[self.df['ì‘ì„±ì'].notna() & (self.df['ì‘ì„±ì'] != '')]
        results = []
        
        for author in valid_data['ì‘ì„±ì'].unique():
            author_data = valid_data[valid_data['ì‘ì„±ì'] == author]
            
            # ê¸°ë³¸ í†µê³„
            total_items = len(author_data)
            decl_grouped = author_data.groupby('ì‹ ê³ ë²ˆí˜¸').first().reset_index()
            unique_declarations = len(decl_grouped)
            
            # ë³µì¡ë„ ì ìˆ˜ ê³„ì‚°
            complexity_score = self.calculate_complexity_score(author_data)
            
            # ê¸°íƒ€ í†µê³„ë“¤
            total_lanes = decl_grouped['ì´ë€ìˆ˜'].fillna(0).astype(int).sum()
            total_specs = decl_grouped['ì´ê·œê²©ìˆ˜'].fillna(0).astype(int).sum()
            
            # ìˆ˜ì…ìš”ê±´ ë¶„ì„
            requirement_count = author_data[author_data['ë°œê¸‰ì„œë¥˜ëª…'].notna()]['ì‹ ê³ ë²ˆí˜¸'].nunique()
            
            # FTA ë¶„ì„
            fta_count = decl_grouped[decl_grouped['ì›ì‚°ì§€ì¦ëª…ìœ ë¬´'] == 'Y']
            fta_rate = len(fta_count) / unique_declarations * 100 if unique_declarations > 0 else 0
            
            # ê°ë©´ ë¶„ì„
            exemption_count = decl_grouped[
                decl_grouped['ê´€ì„¸ê°ë©´êµ¬ë¶„'].notna() & 
                (decl_grouped['ê´€ì„¸ê°ë©´êµ¬ë¶„'].astype(str).str.strip() != '')
            ]
            exemption_rate = (
                len(exemption_count) / unique_declarations * 100
                if unique_declarations > 0 else 0
            )
            
            # ê±°ë˜êµ¬ë¶„ ë° ë¬´ì—­ê±°ë˜ì²˜ ë¶„ì„
            transaction_types = decl_grouped['ê±°ë˜êµ¬ë¶„'].nunique()
            trader_count = decl_grouped['ë¬´ì—­ê±°ë˜ì²˜ìƒí˜¸'].nunique()
            importer_count = decl_grouped['ë‚©ì„¸ììƒí˜¸'].nunique()
            
            # ìš”ì¼ë³„ ë¶„ì„
            weekday_stats = {}
            if 'ìš”ì¼_í•œê¸€' in author_data.columns:
                weekday_data = author_data[author_data['ìš”ì¼_í•œê¸€'].notna()]
                weekday_grouped = weekday_data.groupby('ìš”ì¼_í•œê¸€')['ì‹ ê³ ë²ˆí˜¸'].nunique()
                for day in ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼']:
                    weekday_stats[day] = weekday_grouped.get(day, 0)
            
            results.append({
                'ì‘ì„±ì': author,
                'ì´ì²˜ë¦¬ê±´ìˆ˜': total_items,
                'ê³ ìœ ì‹ ê³ ë²ˆí˜¸ìˆ˜': unique_declarations,
                'ë³µì¡ë„ì ìˆ˜': round(complexity_score, 1),
                'ì´ë€ìˆ˜í•©ê³„': total_lanes,
                'ì´ê·œê²©ìˆ˜í•©ê³„': total_specs,
                'ìˆ˜ì…ìš”ê±´ì‹ ê³ ë²ˆí˜¸ìˆ˜': requirement_count,
                'FTAí™œìš©ë¥ ': round(fta_rate, 1),
                'ê´€ì„¸ê°ë©´ì ìš©ë¥ ': round(exemption_rate, 1),
                'ê±°ë˜êµ¬ë¶„ì¢…ë¥˜ìˆ˜': transaction_types,
                'ë¬´ì—­ê±°ë˜ì²˜ìˆ˜': trader_count,
                'ë‹´ë‹¹ìˆ˜ì…ììˆ˜': importer_count,
                'í‰ê· í’ˆëª©ìˆ˜_ì‹ ê³ ì„œ': (
                    round(total_items / unique_declarations, 1)
                    if unique_declarations > 0 else 0
                ),
                'ì›”ìš”ì¼': weekday_stats.get('ì›”ìš”ì¼', 0),
                'í™”ìš”ì¼': weekday_stats.get('í™”ìš”ì¼', 0),
                'ìˆ˜ìš”ì¼': weekday_stats.get('ìˆ˜ìš”ì¼', 0),
                'ëª©ìš”ì¼': weekday_stats.get('ëª©ìš”ì¼', 0),
                'ê¸ˆìš”ì¼': weekday_stats.get('ê¸ˆìš”ì¼', 0)
            })
        
        result_df = pd.DataFrame(results)
        if not result_df.empty:
            result_df = result_df.sort_values('ë³µì¡ë„ì ìˆ˜', ascending=False)
        
        return result_df
    
    def analyze_by_importer(self):
        """ìˆ˜ì…ìë³„ ë¶„ì„ (ê³ ê°ì‚¬ ê´€ë¦¬ìš©)"""
        if 'ë‚©ì„¸ììƒí˜¸' not in self.df.columns:
            return pd.DataFrame()
        
        valid_data = self.df[self.df['ë‚©ì„¸ììƒí˜¸'].notna() & (self.df['ë‚©ì„¸ììƒí˜¸'] != '')]
        results = []
        
        for importer in valid_data['ë‚©ì„¸ììƒí˜¸'].unique():
            importer_data = valid_data[valid_data['ë‚©ì„¸ììƒí˜¸'] == importer]
            
            # ê¸°ë³¸ í†µê³„
            total_items = len(importer_data)
            decl_grouped = importer_data.groupby('ì‹ ê³ ë²ˆí˜¸').first().reset_index()
            unique_declarations = len(decl_grouped)
            
            # ë³µì¡ë„ ì ìˆ˜ ê³„ì‚°
            complexity_score = self.calculate_complexity_score(importer_data)
            
            # ë‹´ë‹¹ ì‘ì„±ì ë¶„ì„
            author_counts = importer_data['ì‘ì„±ì'].value_counts()
            main_author = author_counts.index[0] if len(author_counts) > 0 else ''
            author_diversity = len(author_counts)
            
            # ì—…ì¢… íŠ¹ì„± ë¶„ì„ (ë°œê¸‰ì„œë¥˜ íŒ¨í„´)
            document_types = importer_data[importer_data['ë°œê¸‰ì„œë¥˜ëª…'].notna()]['ë°œê¸‰ì„œë¥˜ëª…'].nunique()
            requirement_rate = len(importer_data[importer_data['ë°œê¸‰ì„œë¥˜ëª…'].notna()]['ì‹ ê³ ë²ˆí˜¸'].unique()) / unique_declarations * 100 if unique_declarations > 0 else 0
            
            # FTA ë° ê°ë©´ í™œìš© ë¶„ì„
            fta_count = decl_grouped[decl_grouped['ì›ì‚°ì§€ì¦ëª…ìœ ë¬´'] == 'Y']
            fta_rate = len(fta_count) / unique_declarations * 100 if unique_declarations > 0 else 0
            
            exemption_count = decl_grouped[
                decl_grouped['ê´€ì„¸ê°ë©´êµ¬ë¶„'].notna() & 
                (decl_grouped['ê´€ì„¸ê°ë©´êµ¬ë¶„'].astype(str).str.strip() != '')
            ]
            exemption_rate = (
                len(exemption_count) / unique_declarations * 100
                if unique_declarations > 0 else 0
            )
            
            # ê±°ë˜êµ¬ë¶„ ë‹¤ì–‘ì„±
            transaction_types = decl_grouped['ê±°ë˜êµ¬ë¶„'].nunique()
            
            # ìš”ì¼ë³„ íŒ¨í„´
            weekday_stats = {}
            if 'ìš”ì¼_í•œê¸€' in importer_data.columns:
                weekday_data = importer_data[importer_data['ìš”ì¼_í•œê¸€'].notna()]
                weekday_grouped = weekday_data.groupby('ìš”ì¼_í•œê¸€')['ì‹ ê³ ë²ˆí˜¸'].nunique()
                for day in ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼']:
                    weekday_stats[day] = weekday_grouped.get(day, 0)
            
            results.append({
                'ìˆ˜ì…ì': importer,
                'ì´ì²˜ë¦¬ê±´ìˆ˜': total_items,
                'ê³ ìœ ì‹ ê³ ë²ˆí˜¸ìˆ˜': unique_declarations,
                'ë³µì¡ë„ì ìˆ˜': round(complexity_score, 1),
                'ì£¼ë‹´ë‹¹ì‘ì„±ì': main_author,
                'ë‹´ë‹¹ì‘ì„±ììˆ˜': author_diversity,
                'ë°œê¸‰ì„œë¥˜ì¢…ë¥˜ìˆ˜': document_types,
                'ìˆ˜ì…ìš”ê±´ë¹„ìœ¨': round(requirement_rate, 1),
                'FTAí™œìš©ë¥ ': round(fta_rate, 1),
                'ê´€ì„¸ê°ë©´í™œìš©ë¥ ': round(exemption_rate, 1),
                'ê±°ë˜êµ¬ë¶„ë‹¤ì–‘ì„±': transaction_types,
                'í‰ê· í’ˆëª©ìˆ˜_ì‹ ê³ ì„œ': (
                    round(total_items / unique_declarations, 1)
                    if unique_declarations > 0 else 0
                ),
                'ì›”ìš”ì¼': weekday_stats.get('ì›”ìš”ì¼', 0),
                'í™”ìš”ì¼': weekday_stats.get('í™”ìš”ì¼', 0),
                'ìˆ˜ìš”ì¼': weekday_stats.get('ìˆ˜ìš”ì¼', 0),
                'ëª©ìš”ì¼': weekday_stats.get('ëª©ìš”ì¼', 0),
                'ê¸ˆìš”ì¼': weekday_stats.get('ê¸ˆìš”ì¼', 0)
            })
        
        result_df = pd.DataFrame(results)
        if not result_df.empty:
            result_df = result_df.sort_values('ì´ì²˜ë¦¬ê±´ìˆ˜', ascending=False)
        
        return result_df
    
    def analyze_by_forwarder(self):
        """ìš´ì†¡ì£¼ì„ ì¸ë³„ ë¶„ì„ (í¬ì›Œë”© ê´€ë¦¬ìš©)"""
        if 'ìš´ì†¡ì£¼ì„ ì¸ìƒí˜¸' not in self.df.columns:
            return pd.DataFrame()
        
        valid_data = self.df[self.df['ìš´ì†¡ì£¼ì„ ì¸ìƒí˜¸'].notna() & (self.df['ìš´ì†¡ì£¼ì„ ì¸ìƒí˜¸'] != '')]
        results = []
        
        for forwarder in valid_data['ìš´ì†¡ì£¼ì„ ì¸ìƒí˜¸'].unique():
            forwarder_data = valid_data[valid_data['ìš´ì†¡ì£¼ì„ ì¸ìƒí˜¸'] == forwarder]
            
            # ê¸°ë³¸ í†µê³„
            total_items = len(forwarder_data)
            decl_grouped = forwarder_data.groupby('ì‹ ê³ ë²ˆí˜¸').first().reset_index()
            unique_declarations = len(decl_grouped)
            
            # ë³µì¡ë„ ì ìˆ˜ ê³„ì‚°
            complexity_score = self.calculate_complexity_score(forwarder_data)
            
            # ë‹´ë‹¹ ì‘ì„±ì ë¶„ì„ (ì¤‘ë³µì œê±° ì‹ ê³ ë²ˆí˜¸ ê¸°ì¤€)
            author_counts = decl_grouped['ì‘ì„±ì'].value_counts()
            main_author = author_counts.index[0] if len(author_counts) > 0 else ''
            author_diversity = len(author_counts)
            
            # ë‹´ë‹¹ ìˆ˜ì…ì ë¶„ì„ (ì¤‘ë³µì œê±° ì‹ ê³ ë²ˆí˜¸ ê¸°ì¤€)
            importer_counts = decl_grouped['ë‚©ì„¸ììƒí˜¸'].value_counts()
            main_importer = importer_counts.index[0] if len(importer_counts) > 0 else ''
            importer_count = len(importer_counts)
            
            # ë¬´ì—­ê±°ë˜ì²˜ ë‹¤ì–‘ì„±
            trader_count = decl_grouped['ë¬´ì—­ê±°ë˜ì²˜ìƒí˜¸'].nunique()
            
            # í†µê´€ íš¨ìœ¨ì„±
            avg_lanes = decl_grouped['ì´ë€ìˆ˜'].fillna(0).mean()
            avg_specs = decl_grouped['ì´ê·œê²©ìˆ˜'].fillna(0).mean()
            
            # FTA ë° ê°ë©´ ë¶„ì„
            fta_count = decl_grouped[decl_grouped['ì›ì‚°ì§€ì¦ëª…ìœ ë¬´'] == 'Y']
            fta_rate = len(fta_count) / unique_declarations * 100 if unique_declarations > 0 else 0
            
            exemption_count = decl_grouped[
                decl_grouped['ê´€ì„¸ê°ë©´êµ¬ë¶„'].notna() & 
                (decl_grouped['ê´€ì„¸ê°ë©´êµ¬ë¶„'].astype(str).str.strip() != '')
            ]
            exemption_rate = (
                len(exemption_count) / unique_declarations * 100
                if unique_declarations > 0 else 0
            )
            
            # ìš”ì¼ë³„ íŒ¨í„´
            weekday_stats = {}
            if 'ìš”ì¼_í•œê¸€' in forwarder_data.columns:
                weekday_data = forwarder_data[forwarder_data['ìš”ì¼_í•œê¸€'].notna()]
                weekday_grouped = weekday_data.groupby('ìš”ì¼_í•œê¸€')['ì‹ ê³ ë²ˆí˜¸'].nunique()
                for day in ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼']:
                    weekday_stats[day] = weekday_grouped.get(day, 0)
            
            results.append({
                'ìš´ì†¡ì£¼ì„ ì¸': forwarder,
                'ì´ì²˜ë¦¬ê±´ìˆ˜': total_items,
                'ê³ ìœ ì‹ ê³ ë²ˆí˜¸ìˆ˜': unique_declarations,
                'ë³µì¡ë„ì ìˆ˜': round(complexity_score, 1),
                'ì£¼ë‹´ë‹¹ì‘ì„±ì': main_author,
                'ë‹´ë‹¹ì‘ì„±ììˆ˜': author_diversity,
                'ì£¼ìš”ìˆ˜ì…ì': main_importer,
                'ì—°ê²°ìˆ˜ì…ììˆ˜': importer_count,
                'ì—°ê²°ë¬´ì—­ê±°ë˜ì²˜ìˆ˜': trader_count,
                'í‰ê· ë€ìˆ˜_ì‹ ê³ ì„œ': round(avg_lanes, 1),
                'í‰ê· ê·œê²©ìˆ˜_ì‹ ê³ ì„œ': round(avg_specs, 1),
                'FTAí™œìš©ë¥ ': round(fta_rate, 1),
                'ê´€ì„¸ê°ë©´í™œìš©ë¥ ': round(exemption_rate, 1),
                'í‰ê· í’ˆëª©ìˆ˜_ì‹ ê³ ì„œ': (
                    round(total_items / unique_declarations, 1)
                    if unique_declarations > 0 else 0
                ),
                'ì›”ìš”ì¼': weekday_stats.get('ì›”ìš”ì¼', 0),
                'í™”ìš”ì¼': weekday_stats.get('í™”ìš”ì¼', 0),
                'ìˆ˜ìš”ì¼': weekday_stats.get('ìˆ˜ìš”ì¼', 0),
                'ëª©ìš”ì¼': weekday_stats.get('ëª©ìš”ì¼', 0),
                'ê¸ˆìš”ì¼': weekday_stats.get('ê¸ˆìš”ì¼', 0)
            })
        
        result_df = pd.DataFrame(results)
        if not result_df.empty:
            result_df = result_df.sort_values('ì´ì²˜ë¦¬ê±´ìˆ˜', ascending=False)
        
        return result_df
    
    def analyze_cs_inspection(self):
        """C/Sê²€ì‚¬êµ¬ë¶„ë³„ ë¶„ì„"""
        if 'C/Sê²€ì‚¬êµ¬ë¶„' not in self.df.columns:
            return pd.DataFrame(), {}
        
        valid_data = self.df[self.df['C/Sê²€ì‚¬êµ¬ë¶„'].notna()]
        
        # ì‹ ê³ ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µì œê±° (ë” ëª…ì‹œì )
        unique_declarations = valid_data.groupby('ì‹ ê³ ë²ˆí˜¸').first().reset_index()
        
        # ê²€ì‚¬êµ¬ë¶„ë³„ ì‹ ê³ ë²ˆí˜¸ ê°œìˆ˜ (ì¤‘ë³µì œê±° ì™„ë£Œ)
        cs_analysis = unique_declarations.groupby('C/Sê²€ì‚¬êµ¬ë¶„').size().reset_index(name='ì‹ ê³ ë²ˆí˜¸ìˆ˜')
        cs_analysis.columns = ['ê²€ì‚¬êµ¬ë¶„', 'ì‹ ê³ ë²ˆí˜¸ìˆ˜']
        cs_analysis = cs_analysis.sort_values('ì‹ ê³ ë²ˆí˜¸ìˆ˜', ascending=False)
        
        # ê²€ì‚¬êµ¬ë¶„ ë§¤í•‘
        inspection_mapping = {
            'Y': 'ì„¸ê´€ê²€ì‚¬',
            'F': 'í˜‘ì—„ê²€ì‚¬', 
            'N': 'ë¬´ê²€ì‚¬',
            'C': 'ì„œë¥˜ê²€ì‚¬',
            'S': 'í‘œë³¸ê²€ì‚¬'
        }
        
        cs_analysis['ê²€ì‚¬ìœ í˜•'] = cs_analysis['ê²€ì‚¬êµ¬ë¶„'].map(inspection_mapping).fillna('ê¸°íƒ€')
        
        # í†µê³„ ìš”ì•½ (ì¤‘ë³µì œê±°ëœ ë°ì´í„° ê¸°ì¤€)
        total_declarations = len(unique_declarations)
        stats_summary = {
            'ì´ì‹ ê³ ë²ˆí˜¸ìˆ˜': total_declarations,
            'ê²€ì‚¬êµ¬ë¶„ì¢…ë¥˜': len(cs_analysis),
            'ê°€ì¥ë§ì€ê²€ì‚¬': cs_analysis.iloc[0]['ê²€ì‚¬ìœ í˜•'] if not cs_analysis.empty else '',
            'ë¬´ê²€ì‚¬ìœ¨': round(cs_analysis[cs_analysis['ê²€ì‚¬êµ¬ë¶„'] == 'N']['ì‹ ê³ ë²ˆí˜¸ìˆ˜'].sum() / total_declarations * 100, 1) if total_declarations > 0 else 0
        }
        
        return cs_analysis, stats_summary

def create_weekday_chart(df, title, entity_col, entity_name=None):
    """ìš”ì¼ë³„ ì°¨íŠ¸ ìƒì„±"""
    if entity_name:
        entity_data = df[df[entity_col] == entity_name]
    else:
        entity_data = df.head(10)  # ìƒìœ„ 10ê°œ
    
    weekdays = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼']
    
    fig = go.Figure()
    
    for _, row in entity_data.iterrows():
        values = [row.get(day, 0) for day in weekdays]
        fig.add_trace(go.Scatter(
            x=weekdays,
            y=values,
            mode='lines+markers',
            name=row[entity_col],
            line=dict(width=3),
            marker=dict(size=8)
        ))
    
    fig.update_layout(
        title=title,
        xaxis_title="ìš”ì¼",
        yaxis_title="ì‹ ê³ ë²ˆí˜¸ ìˆ˜",
        height=400,
        hovermode='x unified'
    )
    
    return fig

def create_complexity_distribution(df, entity_col):
    """ë³µì¡ë„ ë¶„í¬ ì°¨íŠ¸"""
    fig = px.histogram(
        df,
        x='ë³µì¡ë„ì ìˆ˜',
        title=f"{entity_col} ë³µì¡ë„ ì ìˆ˜ ë¶„í¬",
        nbins=20,
        color_discrete_sequence=['#3498db']
    )
    fig.update_layout(height=400)
    return fig

def create_top_entities_chart(df, entity_col, metric='ì´ì²˜ë¦¬ê±´ìˆ˜', top_n=10):
    """ìƒìœ„ ì—”í‹°í‹° ì°¨íŠ¸"""
    top_df = df.head(top_n)
    
    fig = px.bar(
        top_df,
        x=entity_col,
        y=metric,
        title=f"ìƒìœ„ {top_n}ê°œ {entity_col} - {metric}",
        color=metric,
        text=metric
    )
    fig.update_traces(texttemplate='%{text:,}', textposition='outside')
    fig.update_layout(height=500, xaxis_tickangle=-45)
    return fig

def create_excel_download(df, filename):
    """ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ìƒì„± (í•œê¸€ ê¹¨ì§ ë°©ì§€)"""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='ë¶„ì„ê²°ê³¼')
        # ì›Œí¬ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸°
        worksheet = writer.sheets['ë¶„ì„ê²°ê³¼']
        # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
        for column in worksheet.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = min(max_length + 2, 50)
            worksheet.column_dimensions[column_letter].width = adjusted_width
    
    output.seek(0)
    return output.getvalue()


def create_pdf_download(df, title, filename):
    """PDF íŒŒì¼ ë‹¤ìš´ë¡œë“œ ìƒì„± (ê°€ë¡œ í˜•ì‹, ìë™ í¬ê¸° ì¡°ì •)"""
    buffer = io.BytesIO()
    # ê°€ë¡œ í˜•ì‹(Landscape) í˜ì´ì§€ ì„¤ì •
    doc = SimpleDocTemplate(buffer, pagesize=landscape(A4), 
                            leftMargin=30, rightMargin=30, topMargin=30, bottomMargin=30)
    elements = []
    
    # ìŠ¤íƒ€ì¼ ì„¤ì •
    styles = getSampleStyleSheet()
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontName=KOREAN_FONT,
        fontSize=14,
        spaceAfter=20,
        alignment=1  # ì¤‘ì•™ ì •ë ¬
    )
    
    # ì œëª© ì¶”ê°€
    elements.append(Paragraph(title, title_style))
    elements.append(Spacer(1, 15))
    
    # ë°ì´í„°ë¥¼ í…Œì´ë¸”ë¡œ ë³€í™˜
    if not df.empty:
        # ì»¬ëŸ¼ëª…ì„ í•œê¸€ë¡œ ë³€í™˜ (ê°„ì†Œí™”)
        column_mapping = {
            'ì‘ì„±ì': 'ì‘ì„±ì',
            'ìˆ˜ì…ì': 'ìˆ˜ì…ì', 
            'ìš´ì†¡ì£¼ì„ ì¸': 'ìš´ì†¡ì£¼ì„ ì¸',
            'ì´ì²˜ë¦¬ê±´ìˆ˜': 'ì´ì²˜ë¦¬ê±´ìˆ˜',
            'ê³ ìœ ì‹ ê³ ë²ˆí˜¸ìˆ˜': 'ì‹ ê³ ë²ˆí˜¸ìˆ˜',
            'ë³µì¡ë„ì ìˆ˜': 'ë³µì¡ë„',
            'FTAí™œìš©ë¥ ': 'FTA(%)',
            'ê´€ì„¸ê°ë©´ì ìš©ë¥ ': 'ê°ë©´(%)',
            'ê´€ì„¸ê°ë©´í™œìš©ë¥ ': 'ê°ë©´(%)',
            'ë‹´ë‹¹ìˆ˜ì…ììˆ˜': 'ë‹´ë‹¹ìˆ˜ì…ì',
            'ì£¼ë‹´ë‹¹ì‘ì„±ì': 'ì£¼ë‹´ë‹¹ì',
            'ë‹´ë‹¹ì‘ì„±ììˆ˜': 'ë‹´ë‹¹ììˆ˜',
            'ë°œê¸‰ì„œë¥˜ì¢…ë¥˜ìˆ˜': 'ì„œë¥˜ì¢…ë¥˜',
            'ìˆ˜ì…ìš”ê±´ë¹„ìœ¨': 'ìš”ê±´(%)',
            'ê±°ë˜êµ¬ë¶„ë‹¤ì–‘ì„±': 'ê±°ë˜êµ¬ë¶„',
            'í‰ê· í’ˆëª©ìˆ˜_ì‹ ê³ ì„œ': 'í‰ê· í’ˆëª©',
            'ì£¼ìš”ìˆ˜ì…ì': 'ì£¼ìš”ìˆ˜ì…ì',
            'ì—°ê²°ìˆ˜ì…ììˆ˜': 'ì—°ê²°ìˆ˜ì…ì',
            'ì—°ê²°ë¬´ì—­ê±°ë˜ì²˜ìˆ˜': 'ì—°ê²°ê±°ë˜ì²˜',
            'í‰ê· ë€ìˆ˜_ì‹ ê³ ì„œ': 'í‰ê· ë€ìˆ˜',
            'í‰ê· ê·œê²©ìˆ˜_ì‹ ê³ ì„œ': 'í‰ê· ê·œê²©',
            'ê²€ì‚¬êµ¬ë¶„': 'ê²€ì‚¬êµ¬ë¶„',
            'ê²€ì‚¬ìœ í˜•': 'ê²€ì‚¬ìœ í˜•',
            'ì‹ ê³ ë²ˆí˜¸ìˆ˜': 'ì‹ ê³ ë²ˆí˜¸ìˆ˜',
            'ë¹„ìœ¨(%)': 'ë¹„ìœ¨(%)',
            'ëˆ„ì ë¹„ìœ¨(%)': 'ëˆ„ì (%)'
        }
        
        # ì»¬ëŸ¼ëª… ë³€í™˜
        df_display = df.copy()
        df_display.columns = [column_mapping.get(col, col) for col in df_display.columns]
        
        # ì¤‘ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ (PDF í­ì— ë§ê²Œ)
        important_cols = []
        for col in df_display.columns:
            if col in ['ì‘ì„±ì', 'ìˆ˜ì…ì', 'ìš´ì†¡ì£¼ì„ ì¸', 'ì´ì²˜ë¦¬ê±´ìˆ˜', 'ì‹ ê³ ë²ˆí˜¸ìˆ˜', 'ë³µì¡ë„', 
                      'FTA(%)', 'ê°ë©´(%)', 'ë‹´ë‹¹ìˆ˜ì…ì', 'ì£¼ë‹´ë‹¹ì', 'ê²€ì‚¬ìœ í˜•']:
                important_cols.append(col)
        
        # ì¤‘ìš” ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì²˜ìŒ 8ê°œ ì»¬ëŸ¼ ì‚¬ìš©
        if not important_cols:
            important_cols = df_display.columns[:8].tolist()
        
        # ì„ íƒëœ ì»¬ëŸ¼ë§Œ ì‚¬ìš©
        df_display = df_display[important_cols]
        
        # ë°ì´í„° ì¤€ë¹„ (ìƒìœ„ 25ê°œ)
        data = [df_display.columns.tolist()]  # í—¤ë”
        for _, row in df_display.head(25).iterrows():
            formatted_row = []
            for val in row.values:
                if isinstance(val, float) and not pd.isna(val):
                    if val > 100:
                        formatted_row.append(f"{val:,.0f}")
                    else:
                        formatted_row.append(f"{val:.1f}")
                else:
                    formatted_row.append(str(val) if not pd.isna(val) else "")
            data.append(formatted_row)
        
        # ê°€ë¡œ í˜ì´ì§€ í¬ê¸° ê³„ì‚° (landscape A4: 842x595 í¬ì¸íŠ¸)
        page_width = landscape(A4)[0] - 60  # ì—¬ë°± ì œì™¸
        col_count = len(important_cols)
        col_width = page_width / col_count
        
        # í…Œì´ë¸” ìƒì„± (ìë™ í¬ê¸° ì¡°ì •)
        table = Table(data, colWidths=[col_width] * col_count)
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), '#4472c4'),
            ('TEXTCOLOR', (0, 0), (-1, 0), 'white'),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), KOREAN_FONT),
            ('FONTSIZE', (0, 0), (-1, 0), 8),  # í—¤ë” í°íŠ¸ í¬ê¸° ê°ì†Œ
            ('BOTTOMPADDING', (0, 0), (-1, 0), 8),
            ('TOPPADDING', (0, 0), (-1, 0), 8),
            ('BACKGROUND', (0, 1), (-1, -1), '#f8f9fa'),
            ('FONTNAME', (0, 1), (-1, -1), KOREAN_FONT),
            ('FONTSIZE', (0, 1), (-1, -1), 6),  # ë°ì´í„° í°íŠ¸ í¬ê¸° ê°ì†Œ
            ('GRID', (0, 0), (-1, -1), 0.5, 'black'),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('LEFTPADDING', (0, 0), (-1, -1), 3),
            ('RIGHTPADDING', (0, 0), (-1, -1), 3),
            ('TOPPADDING', (0, 1), (-1, -1), 4),
            ('BOTTOMPADDING', (0, 1), (-1, -1), 4),
        ]))
        
        elements.append(table)
        
        # ì»¬ëŸ¼ ì •ë³´ ì¶”ê°€
        elements.append(Spacer(1, 15))
        info_style = ParagraphStyle(
            'InfoStyle',
            parent=styles['Normal'],
            fontName=KOREAN_FONT,
            fontSize=8,
            alignment=0
        )
        
        info_text = f"ğŸ“Š ì´ {len(df)}ê°œ ë ˆì½”ë“œ ì¤‘ ìƒìœ„ 25ê°œ í‘œì‹œ | í‘œì‹œ ì»¬ëŸ¼: {', '.join(important_cols)}"
        elements.append(Paragraph(info_text, info_style))
    
    # PDF ìƒì„±
    doc.build(elements)
    buffer.seek(0)
    return buffer.getvalue()


def create_html_download(df, title, filename):
    """HTML íŒŒì¼ ë‹¤ìš´ë¡œë“œ ìƒì„±"""
    # ìŠ¤íƒ€ì¼ì´ í¬í•¨ëœ HTML ìƒì„±
    html_content = f"""
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{title}</title>
        <style>
            body {{
                font-family: 'Malgun Gothic', 'ë§‘ì€ ê³ ë”•', sans-serif;
                margin: 20px;
                background-color: #f5f5f5;
            }}
            .container {{
                max-width: 1200px;
                margin: 0 auto;
                background-color: white;
                padding: 20px;
                border-radius: 10px;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }}
            h1 {{
                color: #1f4e79;
                text-align: center;
                border-bottom: 3px solid #4472c4;
                padding-bottom: 10px;
            }}
            table {{
                width: 100%;
                border-collapse: collapse;
                margin: 20px 0;
                font-size: 12px;
            }}
            th, td {{
                border: 1px solid #ddd;
                padding: 8px;
                text-align: center;
            }}
            th {{
                background-color: #4472c4;
                color: white;
                font-weight: bold;
            }}
            tr:nth-child(even) {{
                background-color: #f8f9fa;
            }}
            tr:hover {{
                background-color: #e3f2fd;
            }}
            .info {{
                background-color: #e8f4fd;
                border-left: 4px solid #17a2b8;
                padding: 15px;
                margin: 20px 0;
                border-radius: 5px;
            }}
            .footer {{
                text-align: center;
                margin-top: 30px;
                color: #666;
                font-size: 12px;
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>{title}</h1>
            <div class="info">
                <strong>ìƒì„±ì¼ì‹œ:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}<br>
                <strong>ì´ ë ˆì½”ë“œ ìˆ˜:</strong> {len(df)}ê°œ<br>
                <strong>ì»¬ëŸ¼ ìˆ˜:</strong> {len(df.columns)}ê°œ
            </div>
            {df.to_html(index=False, classes='dataframe', escape=False) if not df.empty else '<p>ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.</p>'}
            <div class="footer">
                ê´€ì„¸ë²•ì¸ ìš°ì‹  ì¢…í•© ë¶„ì„ ì‹œìŠ¤í…œ v2.0<br>
                ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
            </div>
        </div>
    </body>
    </html>
    """
    
    return html_content.encode('utf-8')


def get_download_link(data, filename, file_type):
    """ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±"""
    b64 = base64.b64encode(data).decode()
    return f'<a href="data:application/{file_type};base64,{b64}" download="{filename}">ğŸ“¥ {filename} ë‹¤ìš´ë¡œë“œ</a>'


def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    # í—¤ë”
    st.markdown('<div class="main-header">ğŸ¢ ê´€ì„¸ë²•ì¸ ìš°ì‹  ì¢…í•© ë¶„ì„ ì‹œìŠ¤í…œ</div>', 
                unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader(
            "ì—‘ì…€ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['xlsx', 'xls'],
            help="ìˆ˜ì…ì‹ ê³  ë°ì´í„° ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”"
        )
        
        if uploaded_file:
            st.success("âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ!")
            st.info(f"ğŸ“„ íŒŒì¼ëª…: {uploaded_file.name}")
            st.info(f"ğŸ“ íŒŒì¼ í¬ê¸°: {uploaded_file.size / 1024:.1f} KB")
            
            # íŒŒì¼ ì •ë³´ í‘œì‹œ
            with st.expander("ğŸ“‹ íŒŒì¼ ì •ë³´"):
                st.write(f"**íŒŒì¼ëª…**: {uploaded_file.name}")
                st.write(f"**íŒŒì¼ í¬ê¸°**: {uploaded_file.size / 1024:.1f} KB")
                st.write(f"**íŒŒì¼ íƒ€ì…**: {uploaded_file.type}")
                st.write(f"**ì—…ë¡œë“œ ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        else:
            st.warning("âš ï¸ ë¶„ì„í•  ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")
            
        st.markdown("---")
        
        # ë³µì¡ë„ ì ìˆ˜ ì„¤ì •
        st.header("âš™ï¸ ë³µì¡ë„ ì ìˆ˜ ì„¤ì •")
        with st.expander("ğŸ”§ ì ìˆ˜ ê¸°ì¤€ ì»¤ìŠ¤í„°ë§ˆì´ì§•", expanded=False):
            st.markdown("**7ì°¨ì› ë³µì¡ë„ ê°€ì¤‘ì¹˜ ì„¤ì •**")
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            col1, col2 = st.columns(2)
            
            with col1:
                lane_weight = st.number_input(
                    "ì´ë€ìˆ˜ ê°€ì¤‘ì¹˜", 
                    min_value=0.1, max_value=10.0, 
                    value=st.session_state.get('lane_weight', 1.0), 
                    step=0.1,
                    key='lane_weight',
                    help="ì‹ ê³ ì„œì˜ ì´ ë€ìˆ˜ 1ê°œë‹¹ ì ìˆ˜"
                )
                
                spec_weight = st.number_input(
                    "ì´ê·œê²©ìˆ˜ ê°€ì¤‘ì¹˜", 
                    min_value=0.1, max_value=5.0, 
                    value=st.session_state.get('spec_weight', 0.5), 
                    step=0.1,
                    key='spec_weight',
                    help="ì‹ ê³ ì„œì˜ ì´ ê·œê²©ìˆ˜ 1ê°œë‹¹ ì ìˆ˜"
                )
                
                requirement_weight = st.number_input(
                    "ìˆ˜ì…ìš”ê±´ ê°€ì¤‘ì¹˜", 
                    min_value=1.0, max_value=50.0, 
                    value=st.session_state.get('requirement_weight', 10.0), 
                    step=1.0,
                    key='requirement_weight',
                    help="ìˆ˜ì…ìš”ê±´ ì„œë¥˜ 1ê°œë‹¹ ì ìˆ˜"
                )
                
                exemption_weight = st.number_input(
                    "ê´€ì„¸ê°ë©´ ê°€ì¤‘ì¹˜", 
                    min_value=1.0, max_value=50.0, 
                    value=st.session_state.get('exemption_weight', 10.0), 
                    step=1.0,
                    key='exemption_weight',
                    help="ê´€ì„¸ê°ë©´ ì ìš© ì‹œ ì ìˆ˜"
                )
            
            with col2:
                fta_weight = st.number_input(
                    "FTA ê°€ì¤‘ì¹˜", 
                    min_value=1.0, max_value=50.0, 
                    value=st.session_state.get('fta_weight', 10.0), 
                    step=1.0,
                    key='fta_weight',
                    help="FTA ì›ì‚°ì§€ì¦ëª… ì ìš© ì‹œ ì ìˆ˜"
                )
                
                transaction_weight = st.number_input(
                    "ê±°ë˜êµ¬ë¶„ ê°€ì¤‘ì¹˜", 
                    min_value=1.0, max_value=20.0, 
                    value=st.session_state.get('transaction_weight', 5.0), 
                    step=1.0,
                    key='transaction_weight',
                    help="ê±°ë˜êµ¬ë¶„ ì¢…ë¥˜ 1ê°œë‹¹ ì ìˆ˜"
                )
                
                trader_weight = st.number_input(
                    "ë¬´ì—­ê±°ë˜ì²˜ ê°€ì¤‘ì¹˜", 
                    min_value=1.0, max_value=20.0, 
                    value=st.session_state.get('trader_weight', 5.0), 
                    step=1.0,
                    key='trader_weight',
                    help="ë¬´ì—­ê±°ë˜ì²˜ ì¢…ë¥˜ 1ê°œë‹¹ ì ìˆ˜"
                )
            
            # ë³µì¡ë„ ë¶„ë¥˜ ê¸°ì¤€ ì„¤ì •
            st.markdown("**ë³µì¡ë„ ë¶„ë¥˜ ê¸°ì¤€ ì„¤ì •**")
            col1, col2 = st.columns(2)
            
            with col1:
                low_threshold = st.number_input(
                    "ì¼ë°˜ì—…ë¬´ ìƒí•œì„ ", 
                    min_value=50, max_value=500, value=100, step=10,
                    help="ì´ ì ìˆ˜ ë¯¸ë§Œì€ ì¼ë°˜ì—…ë¬´ë¡œ ë¶„ë¥˜"
                )
            
            with col2:
                high_threshold = st.number_input(
                    "ê³ ë³µì¡ë„ í•˜í•œì„ ", 
                    min_value=100, max_value=1000, value=200, step=10,
                    help="ì´ ì ìˆ˜ ì´ìƒì€ ê³ ë³µì¡ë„ë¡œ ë¶„ë¥˜"
                )
            
            # ê°€ì¤‘ì¹˜ í”„ë¡œí•„
            st.markdown("**í”„ë¦¬ì…‹ í”„ë¡œí•„**")
            profile_col1, profile_col2, profile_col3 = st.columns(3)
            
            with profile_col1:
                if st.button("ğŸ¯ í‘œì¤€ í”„ë¡œí•„"):
                    st.session_state.lane_weight = 1.0
                    st.session_state.spec_weight = 0.5
                    st.session_state.requirement_weight = 10.0
                    st.session_state.exemption_weight = 10.0
                    st.session_state.fta_weight = 10.0
                    st.session_state.transaction_weight = 5.0
                    st.session_state.trader_weight = 5.0
                    st.success("í‘œì¤€ í”„ë¡œí•„ ì ìš©!")
                    st.rerun()
            
            with profile_col2:
                if st.button("âš¡ íš¨ìœ¨ì„± ì¤‘ì‹¬"):
                    st.session_state.lane_weight = 0.5
                    st.session_state.spec_weight = 0.3
                    st.session_state.requirement_weight = 5.0
                    st.session_state.exemption_weight = 5.0
                    st.session_state.fta_weight = 5.0
                    st.session_state.transaction_weight = 2.0
                    st.session_state.trader_weight = 2.0
                    st.success("íš¨ìœ¨ì„± ì¤‘ì‹¬ ì ìš©!")
                    st.rerun()
            
            with profile_col3:
                if st.button("ğŸ”¥ ì „ë¬¸ì„± ì¤‘ì‹¬"):
                    st.session_state.lane_weight = 2.0
                    st.session_state.spec_weight = 1.0
                    st.session_state.requirement_weight = 20.0
                    st.session_state.exemption_weight = 20.0
                    st.session_state.fta_weight = 20.0
                    st.session_state.transaction_weight = 10.0
                    st.session_state.trader_weight = 10.0
                    st.success("ì „ë¬¸ì„± ì¤‘ì‹¬ ì ìš©!")
                    st.rerun()
            
            # í˜„ì¬ ì„¤ì • ìš”ì•½
            st.markdown("**ğŸ“Š í˜„ì¬ ì„¤ì • ìš”ì•½**")
            st.write(f"- ì´ë€ìˆ˜: **{lane_weight}ì /ê°œ**")
            st.write(f"- ì´ê·œê²©ìˆ˜: **{spec_weight}ì /ê°œ**")
            st.write(f"- ìˆ˜ì…ìš”ê±´: **{requirement_weight}ì /ê°œ**")
            st.write(f"- ê´€ì„¸ê°ë©´: **{exemption_weight}ì **")
            st.write(f"- FTAí™œìš©: **{fta_weight}ì **")
            st.write(f"- ê±°ë˜êµ¬ë¶„: **{transaction_weight}ì /ì¢…ë¥˜**")
            st.write(f"- ë¬´ì—­ê±°ë˜ì²˜: **{trader_weight}ì /ì¢…ë¥˜**")
            
            st.markdown(f"**ë¶„ë¥˜ ê¸°ì¤€**: ì¼ë°˜({low_threshold}ì  ë¯¸ë§Œ) / ì¤‘ê°„({low_threshold}-{high_threshold}ì ) / ê³ ë³µì¡ë„({high_threshold}ì  ì´ìƒ)")
            
            # ì‹¤ì‹œê°„ ë³µì¡ë„ ì¬ê³„ì‚° ìŠ¤ìœ„ì¹˜
            use_custom_weights = st.toggle(
                "ğŸ”„ ì»¤ìŠ¤í…€ ê°€ì¤‘ì¹˜ ì ìš©", 
                value=False, 
                help="ì²´í¬í•˜ë©´ ìœ„ì˜ ì„¤ì •ê°’ìœ¼ë¡œ ë³µì¡ë„ë¥¼ ì¬ê³„ì‚°í•©ë‹ˆë‹¤"
            )
            
            if use_custom_weights:
                st.info("ğŸ’¡ ì»¤ìŠ¤í…€ ê°€ì¤‘ì¹˜ê°€ ì ìš©ë©ë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.")
                
                # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ë° ë¶„ì„ ì¬ì‹¤í–‰
                updated_weights = {
                    'lane_weight': lane_weight,
                    'spec_weight': spec_weight,
                    'requirement_weight': requirement_weight,
                    'exemption_weight': exemption_weight,
                    'fta_weight': fta_weight,
                    'transaction_weight': transaction_weight,
                    'trader_weight': trader_weight
                }
                
                analyzer.update_weights(updated_weights)
                
                # ë¶„ì„ ì¬ì‹¤í–‰
                with st.spinner("ğŸ”„ ì»¤ìŠ¤í…€ ê°€ì¤‘ì¹˜ë¡œ ë¶„ì„ì„ ì¬ì‹¤í–‰ ì¤‘..."):
                    author_df = analyzer.analyze_by_author()
                    importer_df = analyzer.analyze_by_importer()
                    forwarder_df = analyzer.analyze_by_forwarder()
                    cs_df, cs_stats = analyzer.analyze_cs_inspection()
                
                st.success("âœ… ì»¤ìŠ¤í…€ ê°€ì¤‘ì¹˜ë¡œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        st.markdown("---")
        st.header("ğŸ“Š ë¶„ì„ ê°œìš”")
        st.markdown("""
        **ğŸ¯ 4ëŒ€ ë¶„ì„ ì¶•**
        
        1ï¸âƒ£ **ì‘ì„±ìë³„ ë¶„ì„**
        - ë‚´ë¶€ ì§ì› ê´€ë¦¬
        - ì—…ë¬´ íš¨ìœ¨ì„± í‰ê°€
        - 7ì°¨ì› ë³µì¡ë„ ë¶„ì„
        
        2ï¸âƒ£ **ìˆ˜ì…ìë³„ ë¶„ì„**  
        - ê³ ê°ì‚¬ ê´€ë¦¬
        - ì„œë¹„ìŠ¤ ìµœì í™”
        - ì—…ì¢…ë³„ íŠ¹ì„±
        
        3ï¸âƒ£ **ìš´ì†¡ì£¼ì„ ì¸ë³„ ë¶„ì„**
        - í¬ì›Œë”© íŒŒíŠ¸ë„ˆ ê´€ë¦¬
        - ë¬¼ë¥˜ íš¨ìœ¨ì„±
        - ì‘ì„±ì/ìˆ˜ì…ì ë§¤ì¹­
        
        4ï¸âƒ£ **ê²€ì‚¬êµ¬ë¶„ ë¶„ì„**
        - C/Sê²€ì‚¬êµ¬ë¶„ë³„ í†µê³„
        - ê²€ì‚¬íŒ¨í„´ ë¶„ì„
        - ìœ„í—˜ë„ ê´€ë¦¬
        """)
    
    if uploaded_file is None:
        st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        with st.expander("ğŸ“‹ ì‹œìŠ¤í…œ ê¸°ëŠ¥ ìƒì„¸"):
            st.markdown("""
            ### ğŸ¯ 7ì°¨ì› ë³µì¡ë„ ë¶„ì„ ì—”ì§„
            **ë³µì¡ë„ = ì´ë€ìˆ˜ + ì´ê·œê²©ìˆ˜ + ìˆ˜ì…ìš”ê±´ìˆ˜ + ê°ë©´ì—¬ë¶€ + ì›ì‚°ì§€ì¦ëª…ì—¬ë¶€ + ê±°ë˜êµ¬ë¶„ì¢…ë¥˜ + ë¬´ì—­ê±°ë˜ì²˜ì¢…ë¥˜**
            
            ### ğŸ“Š 4ì°¨ì› í†µí•© ë¶„ì„
            - **ë‚´ë¶€ ê´€ë¦¬**: ì‘ì„±ìë³„ ì—…ë¬´ ë¶„ë°° ìµœì í™”
            - **ê³ ê° ê´€ë¦¬**: ìˆ˜ì…ìë³„ ë§ì¶¤ ì„œë¹„ìŠ¤ 
            - **íŒŒíŠ¸ë„ˆ ê´€ë¦¬**: ìš´ì†¡ì£¼ì„ ì¸ë³„ í˜‘ë ¥ íš¨ìœ¨í™”
            - **ê²€ì‚¬ ê´€ë¦¬**: C/Sê²€ì‚¬êµ¬ë¶„ë³„ íŒ¨í„´ ë¶„ì„
            
            ### â° ìš”ì¼ë³„ íŒ¨í„´ ë¶„ì„  
            - ì—…ë¬´ëŸ‰ ì˜ˆì¸¡ ë° ì¸ë ¥ ë°°ì¹˜
            - ê³ ê°ë³„ ì‹ ê³  íŒ¨í„´ íŒŒì•…
            - íš¨ìœ¨ì  ìŠ¤ì¼€ì¤„ë§
            
            ### ğŸ” í¬ì›Œë” ìƒì„¸ ë¶„ì„
            - ë‹´ë‹¹ ì‘ì„±ì/ìˆ˜ì…ì ë§¤ì¹­ (ì¤‘ë³µì œê±° ê¸°ì¤€)
            - ë„¤íŠ¸ì›Œí¬ ê´€ê³„ ì‹œê°í™”
            - í˜‘ë ¥ ìµœì í™” ì¸ì‚¬ì´íŠ¸
            """)
        return
    
    # ë°ì´í„° ë¡œë”©
    try:
        with st.spinner("ğŸ“Š ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            # íŒŒì¼ ë¡œë”© ì§„í–‰ìƒí™© í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("ğŸ“ ì—‘ì…€ íŒŒì¼ ì½ëŠ” ì¤‘...")
            df = pd.read_excel(uploaded_file)
            progress_bar.progress(25)
            
            status_text.text("ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
            
            # ê°€ì¤‘ì¹˜ ì„¤ì •
            weights = {
                'lane_weight': lane_weight,
                'spec_weight': spec_weight,
                'requirement_weight': requirement_weight,
                'exemption_weight': exemption_weight,
                'fta_weight': fta_weight,
                'transaction_weight': transaction_weight,
                'trader_weight': trader_weight
            }
            
            analyzer = CustomsAnalyzer(df, weights)
            progress_bar.progress(50)
            
            status_text.text("ğŸ“ˆ ì‘ì„±ìë³„ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
            author_df = analyzer.analyze_by_author()
            progress_bar.progress(65)
            
            status_text.text("ğŸ­ ìˆ˜ì…ìë³„ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
            importer_df = analyzer.analyze_by_importer()
            progress_bar.progress(80)
            
            status_text.text("ğŸš› ìš´ì†¡ì£¼ì„ ì¸ë³„ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
            forwarder_df = analyzer.analyze_by_forwarder()
            progress_bar.progress(90)
            
            status_text.text("ğŸ“‹ ê²€ì‚¬êµ¬ë¶„ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
            cs_df, cs_stats = analyzer.analyze_cs_inspection()
            progress_bar.progress(100)
            
            # ì§„í–‰ìƒí™© ì™„ë£Œ
            status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
            st.success("ğŸ‰ ë°ì´í„° ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # ì ì‹œ í›„ ì§„í–‰ìƒí™© ë°” ì œê±°
            import time
            time.sleep(1)
            progress_bar.empty()
            status_text.empty()
        
        # ë°ì´í„° ê²€ì¦ ë° ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
        st.info(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„° ì •ë³´: {len(df)}í–‰, {len(df.columns)}ì—´")
        
        # ì»¬ëŸ¼ ì •ë³´ í‘œì‹œ (ë””ë²„ê¹…ìš©)
        with st.expander("ğŸ” ë°ì´í„° ì»¬ëŸ¼ ì •ë³´"):
            st.write("**ë°ì´í„° ì»¬ëŸ¼ ëª©ë¡:**")
            for i, col in enumerate(df.columns, 1):
                st.write(f"{i}. {col}")
            
            st.write("**ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:**")
            st.dataframe(df.head(), use_container_width=True)
        
        if author_df.empty and importer_df.empty and forwarder_df.empty and cs_df.empty:
            st.error("âŒ ë¶„ì„í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            
            # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
            st.warning("ğŸ” ë””ë²„ê¹… ì •ë³´:")
            st.write(f"- ì‘ì„±ì ì»¬ëŸ¼ ì¡´ì¬: {'ì‘ì„±ì' in df.columns}")
            st.write(f"- ìˆ˜ì…ì ì»¬ëŸ¼ ì¡´ì¬: {'ë‚©ì„¸ììƒí˜¸' in df.columns}")
            st.write(f"- í¬ì›Œë” ì»¬ëŸ¼ ì¡´ì¬: {'ìš´ì†¡ì£¼ì„ ì¸ìƒí˜¸' in df.columns}")
            st.write(f"- ê²€ì‚¬êµ¬ë¶„ ì»¬ëŸ¼ ì¡´ì¬: {'C/Sê²€ì‚¬êµ¬ë¶„' in df.columns}")
            
            if 'ì‘ì„±ì' in df.columns:
                st.write(f"- ì‘ì„±ì ë°ì´í„° ìƒ˜í”Œ: {df['ì‘ì„±ì'].dropna().head().tolist()}")
            if 'ë‚©ì„¸ììƒí˜¸' in df.columns:
                st.write(f"- ìˆ˜ì…ì ë°ì´í„° ìƒ˜í”Œ: {df['ë‚©ì„¸ììƒí˜¸'].dropna().head().tolist()}")
            if 'ìš´ì†¡ì£¼ì„ ì¸ìƒí˜¸' in df.columns:
                st.write(f"- í¬ì›Œë” ë°ì´í„° ìƒ˜í”Œ: {df['ìš´ì†¡ì£¼ì„ ì¸ìƒí˜¸'].dropna().head().tolist()}")
            
            return
            
    except Exception as e:
        st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        # ìƒì„¸ ì˜¤ë¥˜ ì •ë³´ í‘œì‹œ
        with st.expander("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
            import traceback
            st.code(traceback.format_exc())
        return
    
    # ì „ì²´ ìš”ì•½ í†µê³„
    total_items = len(df)
    total_declarations = df['ì‹ ê³ ë²ˆí˜¸'].nunique()
    total_authors = df['ì‘ì„±ì'].nunique() if 'ì‘ì„±ì' in df.columns else 0
    total_importers = df['ë‚©ì„¸ììƒí˜¸'].nunique() if 'ë‚©ì„¸ììƒí˜¸' in df.columns else 0
    total_forwarders = df['ìš´ì†¡ì£¼ì„ ì¸ìƒí˜¸'].nunique() if 'ìš´ì†¡ì£¼ì„ ì¸ìƒí˜¸' in df.columns else 0
    
    st.header("ğŸ“Š ì „ì²´ í˜„í™© ìš”ì•½")
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("ì´ ì²˜ë¦¬ í’ˆëª©", f"{total_items:,}ê°œ")
    
    with col2:
        st.metric("ì´ ì‹ ê³ ë²ˆí˜¸", f"{total_declarations:,}ê°œ")
    
    with col3:
        st.metric("ë‹´ë‹¹ ì‘ì„±ì", f"{total_authors}ëª…")
    
    with col4:
        st.metric("í˜‘ë ¥ ìˆ˜ì…ì", f"{total_importers}ê°œì‚¬")
    
    with col5:
        st.metric("í˜‘ë ¥ í¬ì›Œë”", f"{total_forwarders}ê°œì‚¬")
    
    # ë©”ì¸ íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ¢ ì‘ì„±ìë³„ ë¶„ì„ (ë‚´ë¶€ê´€ë¦¬)",
        "ğŸ­ ìˆ˜ì…ìë³„ ë¶„ì„ (ê³ ê°ê´€ë¦¬)", 
        "ğŸš› ìš´ì†¡ì£¼ì„ ì¸ë³„ ë¶„ì„ (í¬ì›Œë”©ê´€ë¦¬)",
        "ğŸ“‹ ê¸°íƒ€ ë¶„ì„ (ê²€ì‚¬/í†µê³„)"
    ])
    
    # ========== TAB 1: ì‘ì„±ìë³„ ë¶„ì„ ==========
    with tab1:
        st.markdown('<div class="tab-header internal-tab">ğŸ¢ ì‘ì„±ìë³„ ë¶„ì„ - ë‚´ë¶€ ì§ì› ê´€ë¦¬</div>', 
                   unsafe_allow_html=True)
        
        if author_df.empty:
            st.warning("ì‘ì„±ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ë³µì¡ë„ ë¶„ì„
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # ë³µì¡ë„ ë­í‚¹ ì°¨íŠ¸
                fig_author = create_top_entities_chart(author_df, 'ì‘ì„±ì', 'ë³µì¡ë„ì ìˆ˜', 10)
                st.plotly_chart(fig_author, use_container_width=True)
            
            with col2:
                # ë³µì¡ë„ ë¶„í¬
                fig_dist = create_complexity_distribution(author_df, 'ì‘ì„±ì')
                st.plotly_chart(fig_dist, use_container_width=True)
            
            # ìš”ì¼ë³„ íŒ¨í„´ ë¶„ì„
            st.subheader("ğŸ“… ì‘ì„±ìë³„ ìš”ì¼ ì²˜ë¦¬ íŒ¨í„´")
            
            selected_authors = st.multiselect(
                "ë¶„ì„í•  ì‘ì„±ì ì„ íƒ (ìµœëŒ€ 10ëª…)",
                options=author_df['ì‘ì„±ì'].tolist(),
                default=author_df['ì‘ì„±ì'].head(5).tolist(),
                help="ìš”ì¼ë³„ ì²˜ë¦¬ íŒ¨í„´ì„ ë¶„ì„í•  ì‘ì„±ìë¥¼ ì„ íƒí•˜ì„¸ìš”. ëª¨ë“  ì‘ì„±ìê°€ ê¸°ë³¸ìœ¼ë¡œ í¬í•¨ë©ë‹ˆë‹¤."
            )
            
            if selected_authors:
                fig_weekday = create_weekday_chart(
                    author_df[author_df['ì‘ì„±ì'].isin(selected_authors)],
                    "ì‘ì„±ìë³„ ìš”ì¼ ì²˜ë¦¬ í˜„í™©",
                    'ì‘ì„±ì'
                )
                st.plotly_chart(fig_weekday, use_container_width=True)
            
            # ìƒì„¸ ë°ì´í„° í…Œì´ë¸”
            st.subheader("ğŸ“‹ ì‘ì„±ìë³„ ìƒì„¸ í˜„í™©")
            
            display_columns = [
                'ì‘ì„±ì', 'ì´ì²˜ë¦¬ê±´ìˆ˜', 'ê³ ìœ ì‹ ê³ ë²ˆí˜¸ìˆ˜', 'ë³µì¡ë„ì ìˆ˜', 
                'FTAí™œìš©ë¥ ', 'ê´€ì„¸ê°ë©´ì ìš©ë¥ ', 'ë‹´ë‹¹ìˆ˜ì…ììˆ˜'
            ]
            
            st.dataframe(
                author_df[display_columns].style.format({
                    'ì´ì²˜ë¦¬ê±´ìˆ˜': '{:,}',
                    'ê³ ìœ ì‹ ê³ ë²ˆí˜¸ìˆ˜': '{:,}',
                    'ë³µì¡ë„ì ìˆ˜': '{:.1f}',
                    'FTAí™œìš©ë¥ ': '{:.1f}%',
                    'ê´€ì„¸ê°ë©´ì ìš©ë¥ ': '{:.1f}%',
                    'ë‹´ë‹¹ìˆ˜ì…ììˆ˜': '{:,}'
                }),
                use_container_width=True
            )
            
            # ì‘ì„±ìë³„ ìƒì„¸ ë¶„ì„ ì„¹ì…˜ ì¶”ê°€
            st.subheader("ğŸ” ì‘ì„±ìë³„ ìƒì„¸ ë¶„ì„")
            
            # ì‘ì„±ì ì„ íƒ
            selected_author = st.selectbox(
                "ìƒì„¸ ë¶„ì„í•  ì‘ì„±ì ì„ íƒ",
                options=author_df['ì‘ì„±ì'].tolist(),
                help="ë‹´ë‹¹ ìˆ˜ì…ìì™€ ì‹ ê³ ë²ˆí˜¸ë¥¼ í™•ì¸í•  ì‘ì„±ìë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )
            
            if selected_author:
                # ì„ íƒëœ ì‘ì„±ìì˜ ë°ì´í„° í•„í„°ë§
                author_data = df[df['ì‘ì„±ì'] == selected_author]
                decl_grouped = author_data.groupby('ì‹ ê³ ë²ˆí˜¸').first().reset_index()
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("ì´ ì²˜ë¦¬ ê±´ìˆ˜", f"{len(author_data):,}ê°œ")
                    st.metric("ê³ ìœ  ì‹ ê³ ë²ˆí˜¸", f"{len(decl_grouped):,}ê°œ")
                
                with col2:
                    complexity_score = analyzer.calculate_complexity_score(author_data)
                    st.metric("ë³µì¡ë„ ì ìˆ˜", f"{complexity_score:.1f}")
                    st.metric("ë‹´ë‹¹ ìˆ˜ì…ì", f"{decl_grouped['ë‚©ì„¸ììƒí˜¸'].nunique()}ê°œì‚¬")
                
                with col3:
                    fta_rate = len(decl_grouped[decl_grouped['ì›ì‚°ì§€ì¦ëª…ìœ ë¬´'] == 'Y']) / len(decl_grouped) * 100
                    exemption_rate = len(decl_grouped[
                        decl_grouped['ê´€ì„¸ê°ë©´êµ¬ë¶„'].notna() & 
                        (decl_grouped['ê´€ì„¸ê°ë©´êµ¬ë¶„'].astype(str).str.strip() != '')
                    ]) / len(decl_grouped) * 100
                    st.metric("FTA í™œìš©ë¥ ", f"{fta_rate:.1f}%")
                    st.metric("ê°ë©´ ì ìš©ë¥ ", f"{exemption_rate:.1f}%")
                
                # ë‹´ë‹¹ ìˆ˜ì…ì ëª©ë¡
                st.subheader(f"ğŸ­ {selected_author} ë‹´ë‹¹ ìˆ˜ì…ì ëª©ë¡")
                
                importer_summary = decl_grouped.groupby('ë‚©ì„¸ììƒí˜¸').agg({
                    'ì´ë€ìˆ˜': 'sum',
                    'ì´ê·œê²©ìˆ˜': 'sum',
                    'ì›ì‚°ì§€ì¦ëª…ìœ ë¬´': lambda x: (x == 'Y').sum(),
                    'ê´€ì„¸ê°ë©´êµ¬ë¶„': lambda x: x.notna().sum()
                }).reset_index()
                
                # ì‹ ê³ ë²ˆí˜¸ ìˆ˜ ê³„ì‚° (ê·¸ë£¹ë³„ ê°œìˆ˜)
                importer_summary['ì‹ ê³ ë²ˆí˜¸ìˆ˜'] = decl_grouped.groupby('ë‚©ì„¸ììƒí˜¸').size().values
                
                importer_summary.columns = ['ìˆ˜ì…ì', 'ì´ë€ìˆ˜', 'ì´ê·œê²©ìˆ˜', 'FTAê±´ìˆ˜', 'ê°ë©´ê±´ìˆ˜', 'ì‹ ê³ ë²ˆí˜¸ìˆ˜']
                importer_summary = importer_summary.sort_values('ì‹ ê³ ë²ˆí˜¸ìˆ˜', ascending=False)
                
                # ìˆ˜ì…ìë³„ í†µê³„ í…Œì´ë¸”
                st.dataframe(
                    importer_summary.style.format({
                        'ì‹ ê³ ë²ˆí˜¸ìˆ˜': '{:,}',
                        'ì´ë€ìˆ˜': '{:,}',
                        'ì´ê·œê²©ìˆ˜': '{:,}',
                        'FTAê±´ìˆ˜': '{:,}',
                        'ê°ë©´ê±´ìˆ˜': '{:,}'
                    }),
                    use_container_width=True
                )
                
                # ê³ ìœ  ì‹ ê³ ë²ˆí˜¸ ëª©ë¡
                st.subheader(f"ğŸ“‹ {selected_author} ì²˜ë¦¬ ì‹ ê³ ë²ˆí˜¸ ëª©ë¡")
                
                # ì‹ ê³ ë²ˆí˜¸ë³„ ìƒì„¸ ì •ë³´
                decl_details = decl_grouped[['ì‹ ê³ ë²ˆí˜¸', 'ë‚©ì„¸ììƒí˜¸', 'ìš´ì†¡ì£¼ì„ ì¸ìƒí˜¸', 'ì´ë€ìˆ˜', 'ì´ê·œê²©ìˆ˜', 
                                           'ì›ì‚°ì§€ì¦ëª…ìœ ë¬´', 'ê´€ì„¸ê°ë©´êµ¬ë¶„', 'C/Sê²€ì‚¬êµ¬ë¶„']].copy()
                decl_details = decl_details.sort_values('ì‹ ê³ ë²ˆí˜¸')
                
                # ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€
                search_term = st.text_input(
                    "ì‹ ê³ ë²ˆí˜¸ ë˜ëŠ” ìˆ˜ì…ì ê²€ìƒ‰",
                    placeholder="ì‹ ê³ ë²ˆí˜¸ë‚˜ ìˆ˜ì…ìëª…ì„ ì…ë ¥í•˜ì„¸ìš”"
                )
                
                if search_term:
                    mask = (decl_details['ì‹ ê³ ë²ˆí˜¸'].astype(str).str.contains(search_term, na=False) |
                           decl_details['ë‚©ì„¸ììƒí˜¸'].astype(str).str.contains(search_term, na=False))
                    decl_details = decl_details[mask]
                
                # ì‹ ê³ ë²ˆí˜¸ ëª©ë¡ í…Œì´ë¸”
                st.dataframe(
                    decl_details.style.format({
                        'ì´ë€ìˆ˜': '{:,}',
                        'ì´ê·œê²©ìˆ˜': '{:,}'
                    }),
                    use_container_width=True
                )
                
                # ì‹ ê³ ë²ˆí˜¸ë³„ ìš”ì•½ í†µê³„
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**ğŸ“Š ì‹ ê³ ë²ˆí˜¸ë³„ í†µê³„**")
                    st.write(f"â€¢ ì´ ì‹ ê³ ë²ˆí˜¸: {len(decl_details):,}ê°œ")
                    st.write(f"â€¢ í‰ê·  ë€ìˆ˜: {decl_details['ì´ë€ìˆ˜'].mean():.1f}ë€")
                    st.write(f"â€¢ í‰ê·  ê·œê²©ìˆ˜: {decl_details['ì´ê·œê²©ìˆ˜'].mean():.1f}ê·œê²©")
                    st.write(f"â€¢ FTA í™œìš©: {len(decl_details[decl_details['ì›ì‚°ì§€ì¦ëª…ìœ ë¬´'] == 'Y']):,}ê±´")
                    st.write(f"â€¢ ê°ë©´ ì ìš©: {len(decl_details[decl_details['ê´€ì„¸ê°ë©´êµ¬ë¶„'].notna()]):,}ê±´")
                
                with col2:
                    st.markdown("**ğŸ” ê²€ì‚¬êµ¬ë¶„ë³„ í˜„í™©**")
                    cs_counts = decl_details['C/Sê²€ì‚¬êµ¬ë¶„'].value_counts()
                    for cs_type, count in cs_counts.items():
                        st.write(f"â€¢ {cs_type}: {count:,}ê±´")
                
                # ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
                st.subheader("ğŸ’¾ ìƒì„¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # ìˆ˜ì…ìë³„ ìš”ì•½ ë‹¤ìš´ë¡œë“œ
                    if not importer_summary.empty:
                        excel_data = create_excel_download(importer_summary, f"{selected_author}_ë‹´ë‹¹ìˆ˜ì…ì_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx")
                        st.download_button(
                            f"ğŸ“¥ {selected_author} ë‹´ë‹¹ìˆ˜ì…ì (Excel)",
                            excel_data,
                            f"{selected_author}_ë‹´ë‹¹ìˆ˜ì…ì_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                
                with col2:
                    # ì‹ ê³ ë²ˆí˜¸ë³„ ìƒì„¸ ë‹¤ìš´ë¡œë“œ
                    if not decl_details.empty:
                        excel_data = create_excel_download(decl_details, f"{selected_author}_ì‹ ê³ ë²ˆí˜¸ëª©ë¡_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx")
                        st.download_button(
                            f"ğŸ“¥ {selected_author} ì‹ ê³ ë²ˆí˜¸ëª©ë¡ (Excel)",
                            excel_data,
                            f"{selected_author}_ì‹ ê³ ë²ˆí˜¸ëª©ë¡_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
            
            # ì¸ì‚¬ì´íŠ¸
            st.subheader("ğŸ’¡ ë‚´ë¶€ ê´€ë¦¬ ì¸ì‚¬ì´íŠ¸")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # ë³µì¡ë„ë³„ ë¶„ë¥˜
                high_complexity = author_df[author_df['ë³µì¡ë„ì ìˆ˜'] >= 200]
                medium_complexity = author_df[(author_df['ë³µì¡ë„ì ìˆ˜'] >= 100) & (author_df['ë³µì¡ë„ì ìˆ˜'] < 200)]
                low_complexity = author_df[author_df['ë³µì¡ë„ì ìˆ˜'] < 100]
                
                st.markdown("**ğŸ¯ ì—…ë¬´ ë¶„ë°° ì¶”ì²œ**")
                st.markdown(f"ğŸ”´ ì´ˆê³ ë³µì¡ë„ ë‹´ë‹¹: {len(high_complexity)}ëª…")
                for author in high_complexity['ì‘ì„±ì'].head(3):
                    st.write(f"  â€¢ {author}")
                
                st.markdown(f"ğŸŸ¡ ì¤‘ë³µì¡ë„ ë‹´ë‹¹: {len(medium_complexity)}ëª…")
                for author in medium_complexity['ì‘ì„±ì'].head(3):
                    st.write(f"  â€¢ {author}")
                
                st.markdown(f"ğŸŸ¢ ì¼ë°˜ì—…ë¬´ ë‹´ë‹¹: {len(low_complexity)}ëª…")
                for author in low_complexity['ì‘ì„±ì'].head(3):
                    st.write(f"  â€¢ {author}")
            
            with col2:
                # ì²˜ë¦¬ëŸ‰ ë¶„ì„
                top_performer = author_df.iloc[0]
                most_efficient = author_df.loc[author_df['í‰ê· í’ˆëª©ìˆ˜_ì‹ ê³ ì„œ'].idxmin()]
                
                st.markdown("**ğŸ† ì£¼ìš” ì„±ê³¼ ë¶„ì„**")
                st.markdown(f"ğŸ¥‡ ìµœê³  ë³µì¡ë„: {top_performer['ì‘ì„±ì']} ({top_performer['ë³µì¡ë„ì ìˆ˜']:.1f}ì )")
                st.markdown(f"âš¡ ìµœê³  íš¨ìœ¨ì„±: {most_efficient['ì‘ì„±ì']} ({most_efficient['í‰ê· í’ˆëª©ìˆ˜_ì‹ ê³ ì„œ']:.1f}ê°œ/ì‹ ê³ ì„œ)")
                
                # ë‹´ë‹¹ ê³ ê°ì‚¬ ìˆ˜ ë¶„ì„
                if 'ë‹´ë‹¹ìˆ˜ì…ììˆ˜' in author_df.columns:
                    most_clients = author_df.loc[author_df['ë‹´ë‹¹ìˆ˜ì…ììˆ˜'].idxmax()]
                    st.markdown(f"ğŸ¤ ìµœë‹¤ ê³ ê°: {most_clients['ì‘ì„±ì']} ({most_clients['ë‹´ë‹¹ìˆ˜ì…ììˆ˜']}ê°œì‚¬)")
                
                st.markdown("**ğŸ“Š ë³µì¡ë„ êµ¬ì„± ìš”ì†Œ**")
                st.markdown("â€¢ ì´ë€ìˆ˜ + ì´ê·œê²©ìˆ˜")
                st.markdown("â€¢ ìˆ˜ì…ìš”ê±´ìˆ˜ Ã— 10ì ")
                st.markdown("â€¢ ê°ë©´/FTA/ê±°ë˜êµ¬ë¶„/ë¬´ì—­ê±°ë˜ì²˜")
    
    # ========== TAB 2: ìˆ˜ì…ìë³„ ë¶„ì„ ==========
    with tab2:
        st.markdown('<div class="tab-header client-tab">ğŸ­ ìˆ˜ì…ìë³„ ë¶„ì„ - ê³ ê°ì‚¬ ê´€ë¦¬</div>', 
                   unsafe_allow_html=True)
        
        if importer_df.empty:
            st.warning("ìˆ˜ì…ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ê³ ê°ì‚¬ í˜„í™© ë¶„ì„
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # ì²˜ë¦¬ëŸ‰ ë­í‚¹
                fig_importer = create_top_entities_chart(importer_df, 'ìˆ˜ì…ì', 'ì´ì²˜ë¦¬ê±´ìˆ˜', 10)
                st.plotly_chart(fig_importer, use_container_width=True)
            
            with col2:
                # ë³µì¡ë„ ë¶„í¬
                fig_complexity = create_complexity_distribution(importer_df, 'ìˆ˜ì…ì')
                st.plotly_chart(fig_complexity, use_container_width=True)
            
            # ê³ ê°ë³„ íŠ¹ì„± ë¶„ì„
            st.subheader("ğŸ” ê³ ê°ì‚¬ë³„ ì—…ì¢… íŠ¹ì„± ë¶„ì„")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # ìˆ˜ì…ìš”ê±´ vs ë³µì¡ë„ ìŠ¤ìºí„°
                fig_scatter = px.scatter(
                    importer_df.head(20),
                    x='ìˆ˜ì…ìš”ê±´ë¹„ìœ¨',
                    y='ë³µì¡ë„ì ìˆ˜',
                    size='ì´ì²˜ë¦¬ê±´ìˆ˜',
                    hover_name='ìˆ˜ì…ì',
                    title="ìˆ˜ì…ìš”ê±´ ë¹„ìœ¨ vs ë³µì¡ë„ (ìƒìœ„ 20ê°œì‚¬)",
                    labels={'ìˆ˜ì…ìš”ê±´ë¹„ìœ¨': 'ìˆ˜ì…ìš”ê±´ ë¹„ìœ¨ (%)', 'ë³µì¡ë„ì ìˆ˜': 'ë³µì¡ë„ ì ìˆ˜'}
                )
                st.plotly_chart(fig_scatter, use_container_width=True)
            
            with col2:
                # FTA í™œìš©ë¥  ë¶„í¬
                fig_fta = px.histogram(
                    importer_df,
                    x='FTAí™œìš©ë¥ ',
                    title="ê³ ê°ì‚¬ë³„ FTA í™œìš©ë¥  ë¶„í¬",
                    nbins=20
                )
                st.plotly_chart(fig_fta, use_container_width=True)
            
            # ë‹´ë‹¹ì ë¶„ì„
            st.subheader("ğŸ‘¥ ê³ ê°ì‚¬ë³„ ë‹´ë‹¹ ì‘ì„±ì í˜„í™©")
            
            # ì£¼ìš” ê³ ê°ì‚¬ ì„ íƒ
            top_importers = st.selectbox(
                "ìƒì„¸ ë¶„ì„í•  ê³ ê°ì‚¬ ì„ íƒ",
                options=importer_df['ìˆ˜ì…ì'].head(20).tolist()
            )
            
            if top_importers:
                selected_importer = importer_df[importer_df['ìˆ˜ì…ì'] == top_importers].iloc[0]
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("ì²˜ë¦¬ ê±´ìˆ˜", f"{selected_importer['ì´ì²˜ë¦¬ê±´ìˆ˜']:,}ê°œ")
                    st.metric("ì‹ ê³ ë²ˆí˜¸", f"{selected_importer['ê³ ìœ ì‹ ê³ ë²ˆí˜¸ìˆ˜']:,}ê°œ")
                
                with col2:
                    st.metric("ë³µì¡ë„ ì ìˆ˜", f"{selected_importer['ë³µì¡ë„ì ìˆ˜']:.1f}")
                    st.metric("ì£¼ë‹´ë‹¹ì", selected_importer['ì£¼ë‹´ë‹¹ì‘ì„±ì'])
                
                with col3:
                    st.metric("FTA í™œìš©ë¥ ", f"{selected_importer['FTAí™œìš©ë¥ ']:.1f}%")
                    st.metric("ë°œê¸‰ì„œë¥˜ ì¢…ë¥˜", f"{selected_importer['ë°œê¸‰ì„œë¥˜ì¢…ë¥˜ìˆ˜']}ê°€ì§€")
            
            # ìš”ì¼ë³„ íŒ¨í„´
            st.subheader("ğŸ“… ì£¼ìš” ê³ ê°ì‚¬ ìš”ì¼ë³„ ì‹ ê³  íŒ¨í„´")
            
            selected_importers_pattern = st.multiselect(
                "íŒ¨í„´ ë¶„ì„í•  ê³ ê°ì‚¬ ì„ íƒ",
                options=importer_df['ìˆ˜ì…ì'].head(10).tolist(),
                default=importer_df['ìˆ˜ì…ì'].head(3).tolist()
            )
            
            if selected_importers_pattern:
                fig_weekday_importer = create_weekday_chart(
                    importer_df[importer_df['ìˆ˜ì…ì'].isin(selected_importers_pattern)],
                    "ê³ ê°ì‚¬ë³„ ìš”ì¼ ì‹ ê³  íŒ¨í„´",
                    'ìˆ˜ì…ì'
                )
                st.plotly_chart(fig_weekday_importer, use_container_width=True)
            
            # ì¸ì‚¬ì´íŠ¸
            st.subheader("ğŸ’¡ ê³ ê° ê´€ë¦¬ ì¸ì‚¬ì´íŠ¸")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # VIP ê³ ê° ë¶„ì„
                vip_customers = importer_df[importer_df['ì´ì²˜ë¦¬ê±´ìˆ˜'] >= importer_df['ì´ì²˜ë¦¬ê±´ìˆ˜'].quantile(0.8)]
                complex_customers = importer_df[importer_df['ë³µì¡ë„ì ìˆ˜'] >= 150]
                
                st.markdown("**ğŸ† VIP ê³ ê°ì‚¬ (ìƒìœ„ 20%)**")
                for customer in vip_customers['ìˆ˜ì…ì'].head(5):
                    st.write(f"  â€¢ {customer}")
                
                st.markdown("**âš ï¸ ê³ ë³µì¡ë„ ê³ ê°ì‚¬ (150ì +)**")
                for customer in complex_customers['ìˆ˜ì…ì'].head(5):
                    st.write(f"  â€¢ {customer}")
            
            with col2:
                # ì„œë¹„ìŠ¤ ê°œì„  ì œì•ˆ
                high_requirement = importer_df[importer_df['ìˆ˜ì…ìš”ê±´ë¹„ìœ¨'] >= 70]
                low_fta = importer_df[importer_df['FTAí™œìš©ë¥ '] < 30]
                
                st.markdown("**ğŸ¯ ë§ì¶¤ ì„œë¹„ìŠ¤ ì œì•ˆ**")
                if not high_requirement.empty:
                    st.markdown("ğŸ“‹ ìˆ˜ì…ìš”ê±´ ì»¨ì„¤íŒ… í•„ìš”:")
                    for customer in high_requirement['ìˆ˜ì…ì'].head(3):
                        st.write(f"  â€¢ {customer}")
                
                if not low_fta.empty:
                    st.markdown("ğŸŒ FTA ì»¨ì„¤íŒ… í•„ìš”:")
                    for customer in low_fta['ìˆ˜ì…ì'].head(3):
                        st.write(f"  â€¢ {customer}")
    
    # ========== TAB 3: ìš´ì†¡ì£¼ì„ ì¸ë³„ ë¶„ì„ ==========
    with tab3:
        st.markdown('<div class="tab-header forwarder-tab">ğŸš› ìš´ì†¡ì£¼ì„ ì¸ë³„ ë¶„ì„ - í¬ì›Œë”© íŒŒíŠ¸ë„ˆ ê´€ë¦¬</div>', 
                   unsafe_allow_html=True)
        
        if forwarder_df.empty:
            st.warning("ìš´ì†¡ì£¼ì„ ì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # í¬ì›Œë” í˜„í™© ë¶„ì„
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # ì²˜ë¦¬ëŸ‰ ë­í‚¹
                fig_forwarder = create_top_entities_chart(forwarder_df, 'ìš´ì†¡ì£¼ì„ ì¸', 'ì´ì²˜ë¦¬ê±´ìˆ˜', 10)
                st.plotly_chart(fig_forwarder, use_container_width=True)
            
            with col2:
                # íš¨ìœ¨ì„± ë¶„í¬
                fig_efficiency = px.histogram(
                    forwarder_df,
                    x='í‰ê· í’ˆëª©ìˆ˜_ì‹ ê³ ì„œ',
                    title="í¬ì›Œë”ë³„ ì‹ ê³ ì„œ íš¨ìœ¨ì„± ë¶„í¬",
                    nbins=15
                )
                st.plotly_chart(fig_efficiency, use_container_width=True)
            
            # í¬ì›Œë” íš¨ìœ¨ì„± ë¶„ì„
            st.subheader("âš¡ í¬ì›Œë”ë³„ ì²˜ë¦¬ íš¨ìœ¨ì„± ë¶„ì„")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # í‰ê·  ë€ìˆ˜ vs ë³µì¡ë„
                fig_lanes = px.scatter(
                    forwarder_df.head(20),
                    x='í‰ê· ë€ìˆ˜_ì‹ ê³ ì„œ',
                    y='ë³µì¡ë„ì ìˆ˜',
                    size='ì´ì²˜ë¦¬ê±´ìˆ˜',
                    hover_name='ìš´ì†¡ì£¼ì„ ì¸',
                    title="í‰ê·  ë€ìˆ˜ vs ë³µì¡ë„ (ìƒìœ„ 20ê°œì‚¬)"
                )
                st.plotly_chart(fig_lanes, use_container_width=True)
            
            with col2:
                # ì—°ê²° ë„¤íŠ¸ì›Œí¬ ë¶„ì„
                fig_network = px.scatter(
                    forwarder_df.head(20),
                    x='ì—°ê²°ìˆ˜ì…ììˆ˜',
                    y='ì—°ê²°ë¬´ì—­ê±°ë˜ì²˜ìˆ˜',
                    size='ì´ì²˜ë¦¬ê±´ìˆ˜',
                    hover_name='ìš´ì†¡ì£¼ì„ ì¸',
                    title="ì—°ê²° ë„¤íŠ¸ì›Œí¬ ê·œëª¨ (ìƒìœ„ 20ê°œì‚¬)"
                )
                st.plotly_chart(fig_network, use_container_width=True)
            
            # íŒŒíŠ¸ë„ˆì‹­ ë¶„ì„
            st.subheader("ğŸ¤ í¬ì›Œë”ë³„ ë‹´ë‹¹ í˜„í™© ë¶„ì„")
            
            # ì£¼ìš” í¬ì›Œë” ì„ íƒ
            selected_forwarder = st.selectbox(
                "ìƒì„¸ ë¶„ì„í•  í¬ì›Œë” ì„ íƒ",
                options=forwarder_df['ìš´ì†¡ì£¼ì„ ì¸'].head(15).tolist()
            )
            
            if selected_forwarder:
                forwarder_info = forwarder_df[forwarder_df['ìš´ì†¡ì£¼ì„ ì¸'] == selected_forwarder].iloc[0]
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("ì´ ì²˜ë¦¬ëŸ‰", f"{forwarder_info['ì´ì²˜ë¦¬ê±´ìˆ˜']:,}ê°œ")
                    st.metric("ì‹ ê³ ë²ˆí˜¸", f"{forwarder_info['ê³ ìœ ì‹ ê³ ë²ˆí˜¸ìˆ˜']:,}ê°œ")
                
                with col2:
                    st.metric("ë³µì¡ë„", f"{forwarder_info['ë³µì¡ë„ì ìˆ˜']:.1f}")
                    st.metric("ì£¼ë‹´ë‹¹ì", forwarder_info['ì£¼ë‹´ë‹¹ì‘ì„±ì'])
                
                with col3:
                    st.metric("ì£¼ìš” ìˆ˜ì…ì", forwarder_info['ì£¼ìš”ìˆ˜ì…ì'])
                    st.metric("ì—°ê²° ìˆ˜ì…ì", f"{forwarder_info['ì—°ê²°ìˆ˜ì…ììˆ˜']}ê°œì‚¬")
                
                with col4:
                    st.metric("FTA í™œìš©ë¥ ", f"{forwarder_info['FTAí™œìš©ë¥ ']:.1f}%")
                    st.metric("í‰ê·  íš¨ìœ¨ì„±", f"{forwarder_info['í‰ê· í’ˆëª©ìˆ˜_ì‹ ê³ ì„œ']:.1f}")
                
                # ì„ íƒëœ í¬ì›Œë”ì˜ ë‹´ë‹¹ ì‘ì„±ì ë° ìˆ˜ì…ì ìƒì„¸ ë¶„ì„
                st.subheader(f"ğŸ“Š {selected_forwarder} ìƒì„¸ ë‹´ë‹¹ í˜„í™©")
                
                forwarder_data = df[df['ìš´ì†¡ì£¼ì„ ì¸ìƒí˜¸'] == selected_forwarder]
                decl_grouped = forwarder_data.groupby('ì‹ ê³ ë²ˆí˜¸').first().reset_index()
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # ë‹´ë‹¹ ì‘ì„±ì ë¶„í¬
                    author_dist = decl_grouped['ì‘ì„±ì'].value_counts().head(10)
                    fig_author_dist = px.pie(
                        values=author_dist.values,
                        names=author_dist.index,
                        title=f"{selected_forwarder} ë‹´ë‹¹ ì‘ì„±ì ë¶„í¬",
                        height=400
                    )
                    st.plotly_chart(fig_author_dist, use_container_width=True)
                
                with col2:
                    # ë‹´ë‹¹ ìˆ˜ì…ì ë¶„í¬
                    importer_dist = decl_grouped['ë‚©ì„¸ììƒí˜¸'].value_counts().head(10)
                    fig_importer_dist = px.pie(
                        values=importer_dist.values,
                        names=importer_dist.index,
                        title=f"{selected_forwarder} ë‹´ë‹¹ ìˆ˜ì…ì ë¶„í¬",
                        height=400
                    )
                    st.plotly_chart(fig_importer_dist, use_container_width=True)
            
            # ìš”ì¼ë³„ íŒ¨í„´
            st.subheader("ğŸ“… ì£¼ìš” í¬ì›Œë” ìš”ì¼ë³„ ì²˜ë¦¬ íŒ¨í„´")
            
            selected_forwarders = st.multiselect(
                "íŒ¨í„´ ë¶„ì„í•  í¬ì›Œë” ì„ íƒ",
                options=forwarder_df['ìš´ì†¡ì£¼ì„ ì¸'].head(10).tolist(),
                default=forwarder_df['ìš´ì†¡ì£¼ì„ ì¸'].head(3).tolist()
            )
            
            if selected_forwarders:
                fig_weekday_forwarder = create_weekday_chart(
                    forwarder_df[forwarder_df['ìš´ì†¡ì£¼ì„ ì¸'].isin(selected_forwarders)],
                    "í¬ì›Œë”ë³„ ìš”ì¼ ì²˜ë¦¬ íŒ¨í„´",
                    'ìš´ì†¡ì£¼ì„ ì¸'
                )
                st.plotly_chart(fig_weekday_forwarder, use_container_width=True)
            
            # ì¸ì‚¬ì´íŠ¸
            st.subheader("ğŸ’¡ í¬ì›Œë”© íŒŒíŠ¸ë„ˆ ê´€ë¦¬ ì¸ì‚¬ì´íŠ¸")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # ì£¼ìš” íŒŒíŠ¸ë„ˆ ë¶„ì„
                major_partners = forwarder_df[forwarder_df['ì´ì²˜ë¦¬ê±´ìˆ˜'] >= forwarder_df['ì´ì²˜ë¦¬ê±´ìˆ˜'].quantile(0.8)]
                efficient_partners = forwarder_df[forwarder_df['í‰ê· í’ˆëª©ìˆ˜_ì‹ ê³ ì„œ'] <= 10]
                
                st.markdown("**ğŸ† ì£¼ìš” íŒŒíŠ¸ë„ˆ (ìƒìœ„ 20%)**")
                for partner in major_partners['ìš´ì†¡ì£¼ì„ ì¸'].head(5):
                    st.write(f"  â€¢ {partner}")
                
                st.markdown("**âš¡ ê³ íš¨ìœ¨ íŒŒíŠ¸ë„ˆ (10ê°œ ë¯¸ë§Œ/ì‹ ê³ ì„œ)**")
                for partner in efficient_partners['ìš´ì†¡ì£¼ì„ ì¸'].head(5):
                    st.write(f"  â€¢ {partner}")
            
            with col2:
                # í˜‘ë ¥ ê°•í™” ì œì•ˆ
                high_complexity = forwarder_df[forwarder_df['ë³µì¡ë„ì ìˆ˜'] >= 100]
                diverse_network = forwarder_df[forwarder_df['ì—°ê²°ìˆ˜ì…ììˆ˜'] >= 10]
                
                st.markdown("**ğŸ¯ í˜‘ë ¥ ê°•í™” ì œì•ˆ**")
                if not high_complexity.empty:
                    st.markdown("ğŸ”§ ë³µì¡ì—…ë¬´ ì „ë¬¸ íŒŒíŠ¸ë„ˆ:")
                    for partner in high_complexity['ìš´ì†¡ì£¼ì„ ì¸'].head(3):
                        st.write(f"  â€¢ {partner}")
                
                if not diverse_network.empty:
                    st.markdown("ğŸŒ ë„¤íŠ¸ì›Œí¬ í™•ì¥ íŒŒíŠ¸ë„ˆ:")
                    for partner in diverse_network['ìš´ì†¡ì£¼ì„ ì¸'].head(3):
                        st.write(f"  â€¢ {partner}")
    
    # ========== TAB 4: ê¸°íƒ€ ë¶„ì„ ==========
    with tab4:
        st.markdown('<div class="tab-header">ğŸ“‹ ê¸°íƒ€ ë¶„ì„ - ê²€ì‚¬êµ¬ë¶„ ë° í†µê³„</div>', 
                   unsafe_allow_html=True)
        
        if cs_df.empty:
            st.warning("C/Sê²€ì‚¬êµ¬ë¶„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ì „ì²´ ê²€ì‚¬ í˜„í™© ìš”ì•½
            st.header("ğŸ” C/S ê²€ì‚¬êµ¬ë¶„ ì „ì²´ í˜„í™©")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("ì´ ì‹ ê³ ë²ˆí˜¸", f"{cs_stats['ì´ì‹ ê³ ë²ˆí˜¸ìˆ˜']:,}ê°œ")
            
            with col2:
                st.metric("ê²€ì‚¬êµ¬ë¶„ ì¢…ë¥˜", f"{cs_stats['ê²€ì‚¬êµ¬ë¶„ì¢…ë¥˜']}ì¢…ë¥˜")
            
            with col3:
                st.metric("ì£¼ìš” ê²€ì‚¬ìœ í˜•", cs_stats['ê°€ì¥ë§ì€ê²€ì‚¬'])
            
            with col4:
                st.metric("ë¬´ê²€ì‚¬ìœ¨", f"{cs_stats['ë¬´ê²€ì‚¬ìœ¨']}%")
            
            # ê²€ì‚¬êµ¬ë¶„ë³„ ìƒì„¸ ë¶„ì„
            st.subheader("ğŸ“Š ê²€ì‚¬êµ¬ë¶„ë³„ ìƒì„¸ ë¶„ì„")
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # ê²€ì‚¬êµ¬ë¶„ë³„ ì‹ ê³ ë²ˆí˜¸ ìˆ˜ ë°”ì°¨íŠ¸
                fig_cs = px.bar(
                    cs_df,
                    x='ê²€ì‚¬ìœ í˜•',
                    y='ì‹ ê³ ë²ˆí˜¸ìˆ˜',
                    color='ì‹ ê³ ë²ˆí˜¸ìˆ˜',
                    title="ê²€ì‚¬êµ¬ë¶„ë³„ ì‹ ê³ ë²ˆí˜¸ ìˆ˜",
                    text='ì‹ ê³ ë²ˆí˜¸ìˆ˜',
                    color_continuous_scale='viridis'
                )
                fig_cs.update_traces(texttemplate='%{text:,}', textposition='outside')
                fig_cs.update_layout(height=500)
                st.plotly_chart(fig_cs, use_container_width=True)
            
            with col2:
                # ê²€ì‚¬êµ¬ë¶„ ë¹„ìœ¨ ë„ë„›ì°¨íŠ¸
                fig_cs_pie = px.pie(
                    cs_df,
                    values='ì‹ ê³ ë²ˆí˜¸ìˆ˜',
                    names='ê²€ì‚¬ìœ í˜•',
                    title="ê²€ì‚¬êµ¬ë¶„ ë¹„ìœ¨",
                    hole=0.4,
                    color_discrete_sequence=px.colors.qualitative.Set3
                )
                fig_cs_pie.update_layout(height=500)
                st.plotly_chart(fig_cs_pie, use_container_width=True)
            
            # ìƒì„¸ ë°ì´í„° í…Œì´ë¸”
            st.subheader("ğŸ“‹ ê²€ì‚¬êµ¬ë¶„ë³„ ìƒì„¸ ë°ì´í„°")
            
            # ë¹„ìœ¨ ê³„ì‚° ì¶”ê°€
            cs_df_display = cs_df.copy()
            cs_df_display['ë¹„ìœ¨(%)'] = round(cs_df_display['ì‹ ê³ ë²ˆí˜¸ìˆ˜'] / cs_stats['ì´ì‹ ê³ ë²ˆí˜¸ìˆ˜'] * 100, 1)
            cs_df_display['ëˆ„ì ë¹„ìœ¨(%)'] = cs_df_display['ë¹„ìœ¨(%)'].cumsum()
            
            st.dataframe(
                cs_df_display[['ê²€ì‚¬êµ¬ë¶„', 'ê²€ì‚¬ìœ í˜•', 'ì‹ ê³ ë²ˆí˜¸ìˆ˜', 'ë¹„ìœ¨(%)', 'ëˆ„ì ë¹„ìœ¨(%)']].style.format({
                    'ì‹ ê³ ë²ˆí˜¸ìˆ˜': '{:,}',
                    'ë¹„ìœ¨(%)': '{:.1f}%',
                    'ëˆ„ì ë¹„ìœ¨(%)': '{:.1f}%'
                }),
                use_container_width=True
            )
            
            # ê²€ì‚¬êµ¬ë¶„ë³„ ì¸ì‚¬ì´íŠ¸
            st.subheader("ğŸ’¡ ê²€ì‚¬ íŒ¨í„´ ì¸ì‚¬ì´íŠ¸")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**ğŸ¯ ê²€ì‚¬ íš¨ìœ¨ì„± ë¶„ì„**")
                
                # ë¬´ê²€ì‚¬ vs ê²€ì‚¬ ë¹„ìœ¨
                no_inspection = cs_df[cs_df['ê²€ì‚¬êµ¬ë¶„'] == 'N']['ì‹ ê³ ë²ˆí˜¸ìˆ˜'].sum() if 'N' in cs_df['ê²€ì‚¬êµ¬ë¶„'].values else 0
                total_inspection = cs_stats['ì´ì‹ ê³ ë²ˆí˜¸ìˆ˜'] - no_inspection
                
                st.markdown(f"â€¢ ë¬´ê²€ì‚¬: {no_inspection:,}ê±´ ({cs_stats['ë¬´ê²€ì‚¬ìœ¨']}%)")
                st.markdown(f"â€¢ ê²€ì‚¬ëŒ€ìƒ: {total_inspection:,}ê±´ ({100-cs_stats['ë¬´ê²€ì‚¬ìœ¨']:.1f}%)")
                
                # ê°€ì¥ ë§ì€ ê²€ì‚¬ìœ í˜•
                if not cs_df.empty:
                    top_inspection = cs_df.iloc[0]
                    st.markdown(f"â€¢ ì£¼ìš” ê²€ì‚¬: {top_inspection['ê²€ì‚¬ìœ í˜•']} ({top_inspection['ì‹ ê³ ë²ˆí˜¸ìˆ˜']:,}ê±´)")
            
            with col2:
                st.markdown("**ğŸ“ˆ ê²€ì‚¬ ë¶„í¬ íŠ¹ì„±**")
                
                # ê²€ì‚¬êµ¬ë¶„ ë‹¤ì–‘ì„±
                st.markdown(f"â€¢ ê²€ì‚¬êµ¬ë¶„ ì¢…ë¥˜: {cs_stats['ê²€ì‚¬êµ¬ë¶„ì¢…ë¥˜']}ê°€ì§€")
                
                # ìƒìœ„ 3ê°œ ê²€ì‚¬ìœ í˜•
                top3 = cs_df.head(3)
                top3_total = top3['ì‹ ê³ ë²ˆí˜¸ìˆ˜'].sum()
                top3_ratio = round(top3_total / cs_stats['ì´ì‹ ê³ ë²ˆí˜¸ìˆ˜'] * 100, 1)
                
                st.markdown(f"â€¢ ìƒìœ„ 3ê°œ ê²€ì‚¬ìœ í˜•ì´ ì „ì²´ì˜ {top3_ratio}% ì°¨ì§€")
                
                for i, (_, row) in enumerate(top3.iterrows(), 1):
                    st.markdown(f"  {i}. {row['ê²€ì‚¬ìœ í˜•']}: {row['ì‹ ê³ ë²ˆí˜¸ìˆ˜']:,}ê±´")
            
            # ê²€ì‚¬êµ¬ë¶„ ë§¤í•‘ ì •ë³´
            with st.expander("ğŸ“– ê²€ì‚¬êµ¬ë¶„ ì½”ë“œ ë§¤í•‘ ì •ë³´"):
                st.markdown("""
                **ê²€ì‚¬êµ¬ë¶„ ì½”ë“œ ì„¤ëª…:**
                - **Y**: ì„¸ê´€ê²€ì‚¬ (ë¬¼ë¦¬ê²€ì‚¬)
                - **F**: í˜‘ì—…ê²€ì‚¬ (ê´€ë ¨ê¸°ê´€ í•©ë™ê²€ì‚¬)
                - **N**: ë¬´ê²€ì‚¬ (ì„œë¥˜ì‹¬ì‚¬ë§Œ)
                - **C**: ì„œë¥˜ê²€ì‚¬ (ì„œë¥˜ ì •ë°€ì‹¬ì‚¬)
                - **S**: í‘œë³¸ê²€ì‚¬ (ìƒ˜í”Œ ê²€ì‚¬)
                
                **í™œìš© ë°©ì•ˆ:**
                - ë¬´ê²€ì‚¬ìœ¨ì´ ë†’ì€ ê²½ìš°: ì‹ ë¢°ë„ ë†’ì€ ìˆ˜ì…ì/í’ˆëª©
                - ê²€ì‚¬ìœ¨ì´ ë†’ì€ ê²½ìš°: ìœ„í—˜ë„ ê´€ë¦¬ í•„ìš”
                - í˜‘ì—…ê²€ì‚¬ ë¹„ìœ¨: ë‹¤ë¶€ì²˜ í˜‘ì˜ ì—…ë¬´ëŸ‰ ì˜ˆì¸¡
                """)
        
        # ì¶”ê°€ í†µê³„ ë¶„ì„ (í–¥í›„ í™•ì¥ ê°€ëŠ¥)
        st.subheader("ğŸ“ˆ ì¶”ê°€ í†µê³„ ë¶„ì„")
        
        with st.expander("ğŸ”§ í–¥í›„ í™•ì¥ ê°€ëŠ¥í•œ ë¶„ì„ í•­ëª©"):
            st.markdown("""
            **1. ì‹œê°„ë³„ ë¶„ì„**
            - ì›”ë³„/ì£¼ë³„ ê²€ì‚¬íŒ¨í„´ ë³€í™”
            - ìš”ì¼ë³„ ê²€ì‚¬êµ¬ë¶„ ë¶„í¬
            - ê³„ì ˆì„± ê²€ì‚¬ íŠ¸ë Œë“œ
            
            **2. ìƒê´€ê´€ê³„ ë¶„ì„**  
            - ë³µì¡ë„ vs ê²€ì‚¬êµ¬ë¶„
            - ìˆ˜ì…ìë³„ ê²€ì‚¬íŒ¨í„´
            - ì‘ì„±ìë³„ ê²€ì‚¬ê²°ê³¼
            
            **3. ì˜ˆì¸¡ ëª¨ë¸**
            - ê²€ì‚¬êµ¬ë¶„ ì˜ˆì¸¡ ëª¨ë¸
            - í†µê´€ ì†Œìš”ì‹œê°„ ì˜ˆì¸¡
            - ìœ„í—˜ë„ ìŠ¤ì½”ì–´ë§
            """)
    
    # ì¢…í•© ë‹¤ìš´ë¡œë“œ (4ê°œ íŒŒì¼)
    st.header("ğŸ’¾ ì¢…í•© ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
    
    # ë‹¤ìš´ë¡œë“œ í˜•ì‹ ì„ íƒ
    download_format = st.selectbox(
        "ë‹¤ìš´ë¡œë“œ í˜•ì‹ ì„ íƒ",
        ["ì—‘ì…€ (Excel)", "PDF", "HTML"],
        help="ì›í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”"
    )
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if not author_df.empty:
            if download_format == "ì—‘ì…€ (Excel)":
                excel_data = create_excel_download(author_df, f"ì‘ì„±ìë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx")
                st.download_button(
                    "ğŸ‘¥ ì‘ì„±ì ë¶„ì„ ê²°ê³¼ (Excel)",
                    excel_data,
                    f"ì‘ì„±ìë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            elif download_format == "PDF":
                pdf_data = create_pdf_download(author_df, "ì‘ì„±ìë³„ ë¶„ì„ ê²°ê³¼", f"ì‘ì„±ìë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf")
                st.download_button(
                    "ğŸ‘¥ ì‘ì„±ì ë¶„ì„ ê²°ê³¼ (PDF)",
                    pdf_data,
                    f"ì‘ì„±ìë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                    "application/pdf"
                )
            else:  # HTML
                html_data = create_html_download(author_df, "ì‘ì„±ìë³„ ë¶„ì„ ê²°ê³¼", f"ì‘ì„±ìë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.html")
                st.download_button(
                    "ğŸ‘¥ ì‘ì„±ì ë¶„ì„ ê²°ê³¼ (HTML)",
                    html_data,
                    f"ì‘ì„±ìë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.html",
                    "text/html"
                )
    
    with col2:
        if not importer_df.empty:
            if download_format == "ì—‘ì…€ (Excel)":
                excel_data = create_excel_download(importer_df, f"ìˆ˜ì…ìë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx")
                st.download_button(
                    "ğŸ­ ìˆ˜ì…ì ë¶„ì„ ê²°ê³¼ (Excel)",
                    excel_data,
                    f"ìˆ˜ì…ìë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            elif download_format == "PDF":
                pdf_data = create_pdf_download(importer_df, "ìˆ˜ì…ìë³„ ë¶„ì„ ê²°ê³¼", f"ìˆ˜ì…ìë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf")
                st.download_button(
                    "ğŸ­ ìˆ˜ì…ì ë¶„ì„ ê²°ê³¼ (PDF)",
                    pdf_data,
                    f"ìˆ˜ì…ìë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                    "application/pdf"
                )
            else:  # HTML
                html_data = create_html_download(importer_df, "ìˆ˜ì…ìë³„ ë¶„ì„ ê²°ê³¼", f"ìˆ˜ì…ìë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.html")
                st.download_button(
                    "ğŸ­ ìˆ˜ì…ì ë¶„ì„ ê²°ê³¼ (HTML)",
                    html_data,
                    f"ìˆ˜ì…ìë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.html",
                    "text/html"
                )
    
    with col3:
        if not forwarder_df.empty:
            if download_format == "ì—‘ì…€ (Excel)":
                excel_data = create_excel_download(forwarder_df, f"í¬ì›Œë”ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx")
                st.download_button(
                    "ğŸš› í¬ì›Œë” ë¶„ì„ ê²°ê³¼ (Excel)",
                    excel_data,
                    f"í¬ì›Œë”ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            elif download_format == "PDF":
                pdf_data = create_pdf_download(forwarder_df, "ìš´ì†¡ì£¼ì„ ì¸ë³„ ë¶„ì„ ê²°ê³¼", f"í¬ì›Œë”ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf")
                st.download_button(
                    "ğŸš› í¬ì›Œë” ë¶„ì„ ê²°ê³¼ (PDF)",
                    pdf_data,
                    f"í¬ì›Œë”ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                    "application/pdf"
                )
            else:  # HTML
                html_data = create_html_download(forwarder_df, "ìš´ì†¡ì£¼ì„ ì¸ë³„ ë¶„ì„ ê²°ê³¼", f"í¬ì›Œë”ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.html")
                st.download_button(
                    "ğŸš› í¬ì›Œë” ë¶„ì„ ê²°ê³¼ (HTML)",
                    html_data,
                    f"í¬ì›Œë”ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.html",
                    "text/html"
                )
    
    with col4:
        if not cs_df.empty:
            if download_format == "ì—‘ì…€ (Excel)":
                excel_data = create_excel_download(cs_df, f"ê²€ì‚¬êµ¬ë¶„ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx")
                st.download_button(
                    "ğŸ“‹ ê²€ì‚¬êµ¬ë¶„ ë¶„ì„ ê²°ê³¼ (Excel)",
                    excel_data,
                    f"ê²€ì‚¬êµ¬ë¶„ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            elif download_format == "PDF":
                pdf_data = create_pdf_download(cs_df, "ê²€ì‚¬êµ¬ë¶„ë³„ ë¶„ì„ ê²°ê³¼", f"ê²€ì‚¬êµ¬ë¶„ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf")
                st.download_button(
                    "ğŸ“‹ ê²€ì‚¬êµ¬ë¶„ ë¶„ì„ ê²°ê³¼ (PDF)",
                    pdf_data,
                    f"ê²€ì‚¬êµ¬ë¶„ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                    "application/pdf"
                )
            else:  # HTML
                html_data = create_html_download(cs_df, "ê²€ì‚¬êµ¬ë¶„ë³„ ë¶„ì„ ê²°ê³¼", f"ê²€ì‚¬êµ¬ë¶„ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.html")
                st.download_button(
                    "ğŸ“‹ ê²€ì‚¬êµ¬ë¶„ ë¶„ì„ ê²°ê³¼ (HTML)",
                    html_data,
                    f"ê²€ì‚¬êµ¬ë¶„ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M')}.html",
                    "text/html"
                )
    
    # ì¢…í•© ë¦¬í¬íŠ¸
    st.subheader("ğŸ“„ ì¢…í•© ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ")
    
    report = f"""
ê´€ì„¸ë²•ì¸ ìš°ì‹  ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸
{'='*60}

ğŸ“Š ì „ì²´ í˜„í™© ìš”ì•½
- ì´ ì²˜ë¦¬ í’ˆëª©: {total_items:,}ê°œ
- ì´ ì‹ ê³ ë²ˆí˜¸: {total_declarations:,}ê°œ  
- ë‹´ë‹¹ ì‘ì„±ì: {total_authors}ëª…
- í˜‘ë ¥ ìˆ˜ì…ì: {total_importers}ê°œì‚¬
- í˜‘ë ¥ í¬ì›Œë”: {total_forwarders}ê°œì‚¬

ğŸ¢ ì‘ì„±ìë³„ ë¶„ì„ (ìƒìœ„ 3ëª…)
"""
    if not author_df.empty:
        for i, (_, row) in enumerate(author_df.head(3).iterrows(), 1):
            report += f"{i}. {row['ì‘ì„±ì']}: ë³µì¡ë„ {row['ë³µì¡ë„ì ìˆ˜']:.1f}ì , ì²˜ë¦¬ëŸ‰ {row['ì´ì²˜ë¦¬ê±´ìˆ˜']:,}ê°œ\n"

    report += f"""
ğŸ­ ìˆ˜ì…ìë³„ ë¶„ì„ (ìƒìœ„ 3ê°œì‚¬)
"""
    if not importer_df.empty:
        for i, (_, row) in enumerate(importer_df.head(3).iterrows(), 1):
            report += f"{i}. {row['ìˆ˜ì…ì']}: ë³µì¡ë„ {row['ë³µì¡ë„ì ìˆ˜']:.1f}ì , ì²˜ë¦¬ëŸ‰ {row['ì´ì²˜ë¦¬ê±´ìˆ˜']:,}ê°œ\n"

    report += f"""
ğŸš› í¬ì›Œë”ë³„ ë¶„ì„ (ìƒìœ„ 3ê°œì‚¬)  
"""
    if not forwarder_df.empty:
        for i, (_, row) in enumerate(forwarder_df.head(3).iterrows(), 1):
            report += f"{i}. {row['ìš´ì†¡ì£¼ì„ ì¸']}: ë³µì¡ë„ {row['ë³µì¡ë„ì ìˆ˜']:.1f}ì , ì²˜ë¦¬ëŸ‰ {row['ì´ì²˜ë¦¬ê±´ìˆ˜']:,}ê°œ\n"

    if not cs_df.empty:
        report += f"""
ğŸ“‹ ê²€ì‚¬êµ¬ë¶„ ë¶„ì„
- ì´ ì‹ ê³ ë²ˆí˜¸: {cs_stats['ì´ì‹ ê³ ë²ˆí˜¸ìˆ˜']:,}ê°œ
- ë¬´ê²€ì‚¬ìœ¨: {cs_stats['ë¬´ê²€ì‚¬ìœ¨']}%
- ì£¼ìš” ê²€ì‚¬ìœ í˜•: {cs_stats['ê°€ì¥ë§ì€ê²€ì‚¬']}
"""

    report += f"""

ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸
- 7ì°¨ì› ë³µì¡ë„ ë¶„ì„ìœ¼ë¡œ ì—…ë¬´ ë‚œì´ë„ ì •ëŸ‰í™” ì™„ë£Œ
- ë‚´ë¶€/ê³ ê°/íŒŒíŠ¸ë„ˆ 3ì°¨ì› í†µí•© ê´€ë¦¬ ì²´ê³„ êµ¬ì¶•
- ê²€ì‚¬íŒ¨í„´ ë¶„ì„ìœ¼ë¡œ ìœ„í—˜ë„ ê´€ë¦¬ ìµœì í™” ê°€ëŠ¥

ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ì‹œìŠ¤í…œ: ê´€ì„¸ë²•ì¸ ìš°ì‹  ì¢…í•© ë¶„ì„ ì‹œìŠ¤í…œ v2.0
"""
    
    st.download_button(
        "ğŸ“„ ì¢…í•©ë¦¬í¬íŠ¸ TXT ë‹¤ìš´ë¡œë“œ",
        report,
        f"ìš°ì‹ _ì¢…í•©ë¦¬í¬íŠ¸_{datetime.now().strftime('%Y%m%d_%H%M')}.txt",
        "text/plain"
    )

if __name__ == "__main__":
    main()